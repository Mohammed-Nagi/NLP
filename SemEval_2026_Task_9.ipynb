{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "BvXB-X3HZKhA",
        "v92sHzPf532y",
        "7Higlq0R9aYo",
        "23whIFspsdOc",
        "dmfGYkLq8hI5",
        "duPm5iX08kVc",
        "Nhc58xXgluWi",
        "526rgt4LARqp",
        "y-rKCx6JAOPF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "292148b7c727429db450cb69dc6640dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc648df701294de59cded1bd2a3fe0e8",
              "IPY_MODEL_6d5261c65c1a473abf5b66853c045ea0",
              "IPY_MODEL_a50b27c767344acebba981be5f4cd6a5"
            ],
            "layout": "IPY_MODEL_1aab3b21064549cab950cb45fda3e84b"
          }
        },
        "bc648df701294de59cded1bd2a3fe0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3faa5e63dcf3471995c8f0d8ad3d2692",
            "placeholder": "​",
            "style": "IPY_MODEL_26687174d77e4d33af636fe6f0997c1b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6d5261c65c1a473abf5b66853c045ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d872327781a41c5ae0c319c0d598e07",
            "max": 654186400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c6e7b108e11414f98ae5c4307892c57",
            "value": 654186400
          }
        },
        "a50b27c767344acebba981be5f4cd6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d0f5647a85941d288ba1340b9ad7a98",
            "placeholder": "​",
            "style": "IPY_MODEL_0f82e3b9009a4ce2ae4ffcb726ec16fd",
            "value": " 654M/654M [00:06&lt;00:00, 216MB/s]"
          }
        },
        "1aab3b21064549cab950cb45fda3e84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3faa5e63dcf3471995c8f0d8ad3d2692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26687174d77e4d33af636fe6f0997c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d872327781a41c5ae0c319c0d598e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6e7b108e11414f98ae5c4307892c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d0f5647a85941d288ba1340b9ad7a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f82e3b9009a4ce2ae4ffcb726ec16fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5fc5f459e143f482196c86c80819b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea628eb78d944eac93b3380dd8e95e5d",
              "IPY_MODEL_a011246467614d61b1410f4c7d716f14",
              "IPY_MODEL_95bec357802a4ad08f172a12226ced97"
            ],
            "layout": "IPY_MODEL_5caa88c44f3f416c85f3f6609b059dd2"
          }
        },
        "ea628eb78d944eac93b3380dd8e95e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e50c032cf047b89804c8e35dfecb05",
            "placeholder": "​",
            "style": "IPY_MODEL_b11fffba039b4f74aceeaefc6210452c",
            "value": "model.safetensors: 100%"
          }
        },
        "a011246467614d61b1410f4c7d716f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc0db8e04a14562ab387c416830661d",
            "max": 654164136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3616e535424243c0b3d4efad60932248",
            "value": 654164136
          }
        },
        "95bec357802a4ad08f172a12226ced97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5182e0daf084a089238ca73c2e32c7f",
            "placeholder": "​",
            "style": "IPY_MODEL_7ffa39ac89ac4b559054fbab4403d22e",
            "value": " 654M/654M [00:07&lt;00:00, 179MB/s]"
          }
        },
        "5caa88c44f3f416c85f3f6609b059dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8e50c032cf047b89804c8e35dfecb05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11fffba039b4f74aceeaefc6210452c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dc0db8e04a14562ab387c416830661d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3616e535424243c0b3d4efad60932248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5182e0daf084a089238ca73c2e32c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffa39ac89ac4b559054fbab4403d22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc34106090c4f9c945c88e87de26a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ea5e6db85ca41f6abe40667c2e9470b",
              "IPY_MODEL_1d7c3b8beac8473399b3e99d164bbf47",
              "IPY_MODEL_4c9f424673124f10b0341ce409b25cf0"
            ],
            "layout": "IPY_MODEL_9011e4c36c444a658abf7edd3f419ad8"
          }
        },
        "0ea5e6db85ca41f6abe40667c2e9470b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa8bbc9f03c44a2ab99e3a2c3a15fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d84409a86842f2b89995727d0d584b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1d7c3b8beac8473399b3e99d164bbf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c980014bbe44fada168417484efc7d9",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab791613cbf24089a0423e7a5d0b7579",
            "value": 52
          }
        },
        "4c9f424673124f10b0341ce409b25cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002ea57e97de409eb51e663f43dfbeac",
            "placeholder": "​",
            "style": "IPY_MODEL_79db9f1f6779402480e332289da596e3",
            "value": " 52.0/52.0 [00:00&lt;00:00, 6.22kB/s]"
          }
        },
        "9011e4c36c444a658abf7edd3f419ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa8bbc9f03c44a2ab99e3a2c3a15fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d84409a86842f2b89995727d0d584b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c980014bbe44fada168417484efc7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab791613cbf24089a0423e7a5d0b7579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "002ea57e97de409eb51e663f43dfbeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79db9f1f6779402480e332289da596e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd9309908e2245eeafb4161f47d38b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb2ed6dd0ae945f5b625184de9b56bae",
              "IPY_MODEL_73763438bc7e483c9a5a161d48d2a70d",
              "IPY_MODEL_d0cb8fbc44de428faf0e59ce754ef1d3"
            ],
            "layout": "IPY_MODEL_d3a1212bd4c44c51baf99e8f421925f2"
          }
        },
        "eb2ed6dd0ae945f5b625184de9b56bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50ba45e5bbb04e18bab80635eb58f578",
            "placeholder": "​",
            "style": "IPY_MODEL_a23c7c256a624a2d920a8525398f71c9",
            "value": "config.json: 100%"
          }
        },
        "73763438bc7e483c9a5a161d48d2a70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7aa4d554fd8444aa9522694b8899ec5",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1abddcff37164146bebd508a134f607d",
            "value": 579
          }
        },
        "d0cb8fbc44de428faf0e59ce754ef1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ff491bb7c34b77af8828fd0539268a",
            "placeholder": "​",
            "style": "IPY_MODEL_7438aecd3650463a8595d57ac582d562",
            "value": " 579/579 [00:00&lt;00:00, 61.3kB/s]"
          }
        },
        "d3a1212bd4c44c51baf99e8f421925f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ba45e5bbb04e18bab80635eb58f578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23c7c256a624a2d920a8525398f71c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7aa4d554fd8444aa9522694b8899ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abddcff37164146bebd508a134f607d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ff491bb7c34b77af8828fd0539268a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7438aecd3650463a8595d57ac582d562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf5e361817d407fa6e85603d9c618f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3122c709580a4e878fce01ee1efe807d",
              "IPY_MODEL_0815552710a04da79a63d7c8dfd9448b",
              "IPY_MODEL_d8235d0b451641ddaf83c2830e75e6a2"
            ],
            "layout": "IPY_MODEL_3b231d2bd1074026b84ca08d357d7254"
          }
        },
        "3122c709580a4e878fce01ee1efe807d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0742f20de550411c98cd1be54be54525",
            "placeholder": "​",
            "style": "IPY_MODEL_3c203a94e3f840dc8cd756bd407225ef",
            "value": "spm.model: 100%"
          }
        },
        "0815552710a04da79a63d7c8dfd9448b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6562497ba58479aa393f08e18cc6f29",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6d4e925126a4af8a18c83bfe2645f9b",
            "value": 2464616
          }
        },
        "d8235d0b451641ddaf83c2830e75e6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ba4e3d06104ae58d48283fc97c8fc3",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ce5841b8bb4c7e99d33bc5c498ffdb",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 3.89MB/s]"
          }
        },
        "3b231d2bd1074026b84ca08d357d7254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0742f20de550411c98cd1be54be54525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c203a94e3f840dc8cd756bd407225ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6562497ba58479aa393f08e18cc6f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d4e925126a4af8a18c83bfe2645f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82ba4e3d06104ae58d48283fc97c8fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ce5841b8bb4c7e99d33bc5c498ffdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23b65fa7a434322be261a11c5d0c5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0b4a57b64c347a1a565b5be9a3f07c2",
              "IPY_MODEL_0445a1dce58744db843e6cfd543c30ea",
              "IPY_MODEL_6bf2349dd77e49c7bc2fc981887c740b"
            ],
            "layout": "IPY_MODEL_d94e1042838543a7af398adf5e10f72d"
          }
        },
        "b0b4a57b64c347a1a565b5be9a3f07c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7af778528f412f8fc84db1222a17a3",
            "placeholder": "​",
            "style": "IPY_MODEL_72737253868c4c8588f211f5406cb433",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0445a1dce58744db843e6cfd543c30ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aafbae3e25054a459f4440e718a6b32e",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_487930aa3c71491291f4b828697e501a",
            "value": 371146213
          }
        },
        "6bf2349dd77e49c7bc2fc981887c740b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8b40fbb63e47c48a568c8cf7080a82",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d953413e004138a53fc85763ae1d04",
            "value": " 371M/371M [00:03&lt;00:00, 214MB/s]"
          }
        },
        "d94e1042838543a7af398adf5e10f72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e7af778528f412f8fc84db1222a17a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72737253868c4c8588f211f5406cb433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aafbae3e25054a459f4440e718a6b32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487930aa3c71491291f4b828697e501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd8b40fbb63e47c48a568c8cf7080a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d953413e004138a53fc85763ae1d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b194b84ef8fd41fa85449d588201d8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b157a6325984187a84847bdbbd7bfc7",
              "IPY_MODEL_21934033c3d742329b797b0c50c88ce1",
              "IPY_MODEL_2c7e1a6593b444829dbc8e8941713d36"
            ],
            "layout": "IPY_MODEL_ff683b99f6ee447e9669ccf770c66052"
          }
        },
        "7b157a6325984187a84847bdbbd7bfc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8167a5e7be9429cb9c48202ed76ee82",
            "placeholder": "​",
            "style": "IPY_MODEL_3223c2faa14e449d8dfa9b0768762fb1",
            "value": "model.safetensors: 100%"
          }
        },
        "21934033c3d742329b797b0c50c88ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_976ade26cbc44122b0335c83f7290c2c",
            "max": 371101258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66a0837bb1084e2aaa2ad22cd3bfc94a",
            "value": 371101258
          }
        },
        "2c7e1a6593b444829dbc8e8941713d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9223baa4f81c41ffafc9f37be6b48a90",
            "placeholder": "​",
            "style": "IPY_MODEL_cfc9ba67c3e34ef180a7a76da9b83b52",
            "value": " 371M/371M [00:03&lt;00:00, 265MB/s]"
          }
        },
        "ff683b99f6ee447e9669ccf770c66052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8167a5e7be9429cb9c48202ed76ee82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3223c2faa14e449d8dfa9b0768762fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "976ade26cbc44122b0335c83f7290c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a0837bb1084e2aaa2ad22cd3bfc94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9223baa4f81c41ffafc9f37be6b48a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc9ba67c3e34ef180a7a76da9b83b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb86a554ed5d4abb8b4f338827cb305f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce519754f49b491784fe62512c96eada",
              "IPY_MODEL_9a215e7a98384821a2b66439300527e2",
              "IPY_MODEL_b1743b7e790c45a5bef6dde259eba05a"
            ],
            "layout": "IPY_MODEL_6b7cc17b4ad54d38b8536600d6b91792"
          }
        },
        "ce519754f49b491784fe62512c96eada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_152bc6d18d74443abfd7609a42e98b23",
            "placeholder": "​",
            "style": "IPY_MODEL_59065b9732a9435789ac077f35dcbf8d",
            "value": "model.safetensors: 100%"
          }
        },
        "9a215e7a98384821a2b66439300527e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d7bed6f5514cbe9dd6808a3e190089",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c8800b7a4d64232bcdf6dcf1339ea4e",
            "value": 714290682
          }
        },
        "b1743b7e790c45a5bef6dde259eba05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2d592e20f540ed8691150a83a2a63a",
            "placeholder": "​",
            "style": "IPY_MODEL_d19449e627144150936cf82112d6695c",
            "value": " 714M/714M [00:06&lt;00:00, 233MB/s]"
          }
        },
        "6b7cc17b4ad54d38b8536600d6b91792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152bc6d18d74443abfd7609a42e98b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59065b9732a9435789ac077f35dcbf8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d7bed6f5514cbe9dd6808a3e190089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c8800b7a4d64232bcdf6dcf1339ea4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e2d592e20f540ed8691150a83a2a63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19449e627144150936cf82112d6695c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BvXB-X3HZKhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "piEm3VmYA6XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6deec8e7-d385-4473-d5f9-179f715d8901",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.12/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gc # Garbage collection to manage memory\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "-TtpKwGUKuNk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Disable wandb logging for this script\n",
        "wandb.init(mode=\"disabled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "VT-Z43OUZQqO",
        "outputId": "92ea1382-bb8d-4667-f22d-b95fae5588f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/jf046uc3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d09959e6780>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRGTcepoonVp",
        "outputId": "12aa62e0-274c-4b4c-a42e-c27a77043aa8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "v92sHzPf532y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Plots"
      ],
      "metadata": {
        "id": "7Higlq0R9aYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Comprehensive EDA for SemEval-2026 Task 9 Paper\n",
        "Generates publication-quality SVG plots for LaTeX import\n",
        "\n",
        "Fixed: DataFrame truth value ambiguity error\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Path\n",
        "    BASE_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase\"\n",
        "    OUTPUT_DIR = \"./paper_figures\"\n",
        "\n",
        "    # File paths\n",
        "    FILES = {\n",
        "        'eng_s1_train': f\"{BASE_PATH}/subtask1/train/eng.csv\",\n",
        "        'arb_s1_train': f\"{BASE_PATH}/subtask1/train/arb.csv\",\n",
        "        'eng_s2_train': f\"{BASE_PATH}/subtask2/train/eng.csv\",\n",
        "        'arb_s2_train': f\"{BASE_PATH}/subtask2/train/arb.csv\",\n",
        "        'eng_s3_train': f\"{BASE_PATH}/subtask3/train/eng.csv\",\n",
        "        'arb_s3_train': f\"{BASE_PATH}/subtask3/train/arb.csv\",\n",
        "    }\n",
        "\n",
        "    # Label definitions (from your CSVs)\n",
        "    LABELS = {\n",
        "        's1': ['polarization'],\n",
        "        's2': ['political', 'racial/ethnic', 'religious', 'gender/sexual', 'other'],\n",
        "        's3': ['stereotype', 'vilification', 'dehumanization',\n",
        "               'extreme_language', 'lack_of_empathy', 'invalidation']\n",
        "    }\n",
        "\n",
        "    # Plot styling for academic papers\n",
        "    STYLE = {\n",
        "        'figure.figsize': (10, 6),\n",
        "        'font.size': 11,\n",
        "        'axes.labelsize': 12,\n",
        "        'axes.titlesize': 13,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'legend.fontsize': 10,\n",
        "        'font.family': 'serif',\n",
        "        'font.serif': ['Times New Roman', 'DejaVu Serif'],\n",
        "    }\n",
        "\n",
        "# Apply styling\n",
        "plt.rcParams.update(Config.STYLE)\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "# Create output directory\n",
        "Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ==========================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ==========================================\n",
        "def save_figure(fig, filename, dpi=300):\n",
        "    \"\"\"Save figure as high-quality SVG\"\"\"\n",
        "    filepath = Path(Config.OUTPUT_DIR) / filename\n",
        "    fig.savefig(filepath, format='svg', bbox_inches='tight', dpi=dpi)\n",
        "    print(f\"✅ Saved: {filepath}\")\n",
        "    plt.close(fig)\n",
        "\n",
        "def load_data(key):\n",
        "    \"\"\"Load and validate data\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(Config.FILES[key])\n",
        "        print(f\"✅ Loaded {key}: {len(df)} samples\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading {key}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 1: CLASS IMBALANCE COMPARISON\n",
        "# ==========================================\n",
        "def plot_imbalance_comparison():\n",
        "    \"\"\"\n",
        "    Figure for Section 2.1: Class Distribution Imbalance\n",
        "    Justifies need for Focal Loss\n",
        "    \"\"\"\n",
        "    # Load Subtask 2 data (most imbalanced)\n",
        "    eng_s2 = load_data('eng_s2_train')\n",
        "    arb_s2 = load_data('arb_s2_train')\n",
        "\n",
        "    if eng_s2 is None or arb_s2 is None:\n",
        "        return\n",
        "\n",
        "    labels = Config.LABELS['s2']\n",
        "\n",
        "    # Calculate distributions\n",
        "    eng_dist = eng_s2[labels].sum().sort_values(ascending=False)\n",
        "    arb_dist = arb_s2[labels].sum().sort_values(ascending=False)\n",
        "\n",
        "    # Create figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # English\n",
        "    bars1 = ax1.barh(range(len(eng_dist)), eng_dist.values, color='steelblue', alpha=0.8)\n",
        "    ax1.set_yticks(range(len(eng_dist)))\n",
        "    ax1.set_yticklabels(eng_dist.index)\n",
        "    ax1.set_xlabel('Sample Count')\n",
        "    ax1.set_title('(a) English Subtask 2', fontweight='bold')\n",
        "    ax1.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Add count labels\n",
        "    for i, (bar, val) in enumerate(zip(bars1, eng_dist.values)):\n",
        "        pct = 100 * val / len(eng_s2)\n",
        "        ax1.text(val + 20, i, f'{val} ({pct:.1f}%)',\n",
        "                va='center', fontsize=9)\n",
        "\n",
        "    # Calculate and display imbalance ratio\n",
        "    eng_ratio = eng_dist.max() / eng_dist.min()\n",
        "    ax1.text(0.02, 0.98, f'Imbalance: {eng_ratio:.1f}:1',\n",
        "            transform=ax1.transAxes, va='top', fontsize=10,\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # Arabic\n",
        "    bars2 = ax2.barh(range(len(arb_dist)), arb_dist.values, color='coral', alpha=0.8)\n",
        "    ax2.set_yticks(range(len(arb_dist)))\n",
        "    ax2.set_yticklabels(arb_dist.index)\n",
        "    ax2.set_xlabel('Sample Count')\n",
        "    ax2.set_title('(b) Arabic Subtask 2', fontweight='bold')\n",
        "    ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    for i, (bar, val) in enumerate(zip(bars2, arb_dist.values)):\n",
        "        pct = 100 * val / len(arb_s2)\n",
        "        ax2.text(val + 20, i, f'{val} ({pct:.1f}%)',\n",
        "                va='center', fontsize=9)\n",
        "\n",
        "    arb_ratio = arb_dist.max() / arb_dist.min()\n",
        "    ax2.text(0.02, 0.98, f'Imbalance: {arb_ratio:.1f}:1',\n",
        "            transform=ax2.transAxes, va='top', fontsize=10,\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.suptitle('Distribution of Polarization Categories in Training Set',\n",
        "                fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_figure(fig, 'fig1_class_imbalance.svg')\n",
        "\n",
        "    # Print stats for paper\n",
        "    print(f\"\\n📊 Imbalance Statistics for Paper:\")\n",
        "    print(f\"English: {eng_ratio:.1f}:1 ratio\")\n",
        "    print(f\"Arabic: {arb_ratio:.1f}:1 ratio\")\n",
        "    print(f\"English most common: {eng_dist.index[0]} ({100*eng_dist.iloc[0]/len(eng_s2):.1f}%)\")\n",
        "    print(f\"English least common: {eng_dist.index[-1]} ({100*eng_dist.iloc[-1]/len(eng_s2):.1f}%)\")\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 2: LABEL CO-OCCURRENCE HEATMAP\n",
        "# ==========================================\n",
        "def plot_label_cooccurrence():\n",
        "    \"\"\"\n",
        "    Figure for Section 2.2: Label Co-occurrence\n",
        "    Shows correlation between labels\n",
        "    \"\"\"\n",
        "    # Use Subtask 3 (manifestations have high correlation)\n",
        "    arb_s3 = load_data('arb_s3_train')\n",
        "\n",
        "    if arb_s3 is None:\n",
        "        return\n",
        "\n",
        "    labels = Config.LABELS['s3']\n",
        "\n",
        "    # Calculate correlation\n",
        "    corr_matrix = arb_s3[labels].corr()\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Custom colormap for better visibility\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
        "\n",
        "    sns.heatmap(corr_matrix,\n",
        "                annot=True,\n",
        "                fmt='.3f',\n",
        "                cmap='RdYlBu_r',\n",
        "                center=0,\n",
        "                square=True,\n",
        "                linewidths=1,\n",
        "                cbar_kws={\"shrink\": 0.8, \"label\": \"Pearson Correlation\"},\n",
        "                vmin=-0.2, vmax=1.0,\n",
        "                mask=mask,\n",
        "                ax=ax)\n",
        "\n",
        "    ax.set_title('Label Co-occurrence in Arabic Subtask 3\\n(Lower triangle shows Pearson correlation)',\n",
        "                fontweight='bold', pad=20)\n",
        "\n",
        "    # Highlight high correlations\n",
        "    high_corr = []\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(i+1, len(labels)):\n",
        "            if corr_matrix.iloc[i, j] > 0.6:\n",
        "                high_corr.append((labels[i], labels[j], corr_matrix.iloc[i, j]))\n",
        "\n",
        "    # Add note about high correlations\n",
        "    note_text = \"Strong correlations (r > 0.6):\\n\"\n",
        "    for label1, label2, corr in sorted(high_corr, key=lambda x: x[2], reverse=True)[:3]:\n",
        "        note_text += f\"• {label1} ↔ {label2}: {corr:.3f}\\n\"\n",
        "\n",
        "    plt.text(0.02, -0.15, note_text.strip(), transform=ax.transAxes,\n",
        "            fontsize=9, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_figure(fig, 'fig2_label_correlation.svg')\n",
        "\n",
        "    print(f\"\\n📊 High Correlations for Paper:\")\n",
        "    for label1, label2, corr in sorted(high_corr, key=lambda x: x[2], reverse=True):\n",
        "        print(f\"  {label1} ↔ {label2}: r = {corr:.3f}\")\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 3: TEXT LENGTH DISTRIBUTION\n",
        "# ==========================================\n",
        "def plot_text_length_comparison():\n",
        "    \"\"\"\n",
        "    Shows text length differences between languages\n",
        "    Justifies max_length parameter choice\n",
        "    \"\"\"\n",
        "    # Load all Subtask 2 data\n",
        "    eng_s2 = load_data('eng_s2_train')\n",
        "    arb_s2 = load_data('arb_s2_train')\n",
        "\n",
        "    if eng_s2 is None or arb_s2 is None:\n",
        "        return\n",
        "\n",
        "    # Calculate word counts\n",
        "    eng_s2['word_count'] = eng_s2['text'].str.split().str.len()\n",
        "    arb_s2['word_count'] = arb_s2['text'].str.split().str.len()\n",
        "\n",
        "    # Create figure\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # English\n",
        "    ax1.hist(eng_s2['word_count'], bins=40, color='steelblue',\n",
        "            alpha=0.7, edgecolor='black', density=True)\n",
        "    ax1.axvline(eng_s2['word_count'].mean(), color='red',\n",
        "               linestyle='--', linewidth=2, label=f\"Mean: {eng_s2['word_count'].mean():.1f}\")\n",
        "    ax1.axvline(eng_s2['word_count'].quantile(0.95), color='orange',\n",
        "               linestyle='--', linewidth=2, label=f\"95th %ile: {eng_s2['word_count'].quantile(0.95):.0f}\")\n",
        "    ax1.set_xlabel('Word Count')\n",
        "    ax1.set_ylabel('Density')\n",
        "    ax1.set_title('(a) English Text Length', fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # Arabic\n",
        "    ax2.hist(arb_s2['word_count'], bins=40, color='coral',\n",
        "            alpha=0.7, edgecolor='black', density=True)\n",
        "    ax2.axvline(arb_s2['word_count'].mean(), color='red',\n",
        "               linestyle='--', linewidth=2, label=f\"Mean: {arb_s2['word_count'].mean():.1f}\")\n",
        "    ax2.axvline(arb_s2['word_count'].quantile(0.95), color='orange',\n",
        "               linestyle='--', linewidth=2, label=f\"95th %ile: {arb_s2['word_count'].quantile(0.95):.0f}\")\n",
        "    ax2.set_xlabel('Word Count')\n",
        "    ax2.set_ylabel('Density')\n",
        "    ax2.set_title('(b) Arabic Text Length', fontweight='bold')\n",
        "    ax2.legend()\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Text Length Distribution (Words per Sample)',\n",
        "                fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_figure(fig, 'fig3_text_length.svg')\n",
        "\n",
        "    print(f\"\\n📊 Text Length Stats for Paper:\")\n",
        "    print(f\"English: mean={eng_s2['word_count'].mean():.1f}, \"\n",
        "          f\"median={eng_s2['word_count'].median():.1f}, \"\n",
        "          f\"95th={eng_s2['word_count'].quantile(0.95):.0f}\")\n",
        "    print(f\"Arabic: mean={arb_s2['word_count'].mean():.1f}, \"\n",
        "          f\"median={arb_s2['word_count'].median():.1f}, \"\n",
        "          f\"95th={arb_s2['word_count'].quantile(0.95):.0f}\")\n",
        "\n",
        "# ==========================================\n",
        "# FIGURE 4: MULTI-LABEL COMPLEXITY\n",
        "# ==========================================\n",
        "def plot_multilabel_complexity():\n",
        "    \"\"\"\n",
        "    Shows distribution of labels per sample\n",
        "    Demonstrates multi-label classification challenge\n",
        "    \"\"\"\n",
        "    eng_s2 = load_data('eng_s2_train')\n",
        "    arb_s2 = load_data('arb_s2_train')\n",
        "    eng_s3 = load_data('eng_s3_train')\n",
        "    arb_s3 = load_data('arb_s3_train')\n",
        "\n",
        "    # FIXED: Check each DataFrame individually instead of using 'in' operator\n",
        "    if eng_s2 is None or arb_s2 is None or eng_s3 is None or arb_s3 is None:\n",
        "        return\n",
        "\n",
        "    # Calculate labels per sample\n",
        "    datasets = {\n",
        "        'English S2': eng_s2[Config.LABELS['s2']].sum(axis=1),\n",
        "        'Arabic S2': arb_s2[Config.LABELS['s2']].sum(axis=1),\n",
        "        'English S3': eng_s3[Config.LABELS['s3']].sum(axis=1),\n",
        "        'Arabic S3': arb_s3[Config.LABELS['s3']].sum(axis=1),\n",
        "    }\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, (name, data) in enumerate(datasets.items()):\n",
        "        ax = axes[idx]\n",
        "\n",
        "        # Count distribution\n",
        "        counts = data.value_counts().sort_index()\n",
        "\n",
        "        bars = ax.bar(counts.index, counts.values,\n",
        "                     color='steelblue' if 'English' in name else 'coral',\n",
        "                     alpha=0.7, edgecolor='black')\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{int(height)}',\n",
        "                   ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # Stats\n",
        "        mean_labels = data.mean()\n",
        "        zero_pct = 100 * (data == 0).sum() / len(data)\n",
        "        multi_pct = 100 * (data > 1).sum() / len(data)\n",
        "\n",
        "        stats_text = f\"Mean: {mean_labels:.2f}\\nNo labels: {zero_pct:.1f}%\\nMulti-label: {multi_pct:.1f}%\"\n",
        "        ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,\n",
        "               verticalalignment='top', horizontalalignment='right',\n",
        "               fontsize=9, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
        "\n",
        "        ax.set_xlabel('Number of Labels')\n",
        "        ax.set_ylabel('Number of Samples')\n",
        "        ax.set_title(f'({chr(97+idx)}) {name}', fontweight='bold')\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Multi-Label Complexity: Labels per Sample',\n",
        "                fontsize=14, fontweight='bold', y=1.00)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_figure(fig, 'fig4_multilabel_complexity.svg')\n",
        "\n",
        "# ==========================================\n",
        "# TABLE 1: DATASET STATISTICS\n",
        "# ==========================================\n",
        "def generate_dataset_stats_table():\n",
        "    \"\"\"\n",
        "    Generates comprehensive statistics table for paper\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"TABLE: DATASET STATISTICS (Copy to LaTeX)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    stats = []\n",
        "\n",
        "    for subtask in ['s1', 's2', 's3']:\n",
        "        for lang in ['eng', 'arb']:\n",
        "            key = f\"{lang}_{subtask}_train\"\n",
        "            df = load_data(key)\n",
        "\n",
        "            if df is None:\n",
        "                continue\n",
        "\n",
        "            labels = Config.LABELS[subtask]\n",
        "\n",
        "            # Calculate stats\n",
        "            n_samples = len(df)\n",
        "            word_counts = df['text'].str.split().str.len()\n",
        "            mean_len = word_counts.mean()\n",
        "            median_len = word_counts.median()\n",
        "\n",
        "            if subtask == 's1':\n",
        "                pos_pct = 100 * df[labels[0]].mean()\n",
        "                stats.append({\n",
        "                    'Subtask': subtask.upper(),\n",
        "                    'Lang': lang.upper(),\n",
        "                    'Samples': n_samples,\n",
        "                    'Avg Length': f'{mean_len:.1f}',\n",
        "                    'Positive %': f'{pos_pct:.1f}',\n",
        "                    'Imbalance': '-'\n",
        "                })\n",
        "            else:\n",
        "                label_sums = df[labels].sum(axis=1)\n",
        "                no_label_pct = 100 * (label_sums == 0).sum() / n_samples\n",
        "                multi_pct = 100 * (label_sums > 1).sum() / n_samples\n",
        "                avg_labels = label_sums.mean()\n",
        "\n",
        "                # Imbalance\n",
        "                counts = df[labels].sum()\n",
        "                imbalance = counts.max() / counts.min()\n",
        "\n",
        "                stats.append({\n",
        "                    'Subtask': subtask.upper(),\n",
        "                    'Lang': lang.upper(),\n",
        "                    'Samples': n_samples,\n",
        "                    'Avg Length': f'{mean_len:.1f}',\n",
        "                    'No Labels %': f'{no_label_pct:.1f}',\n",
        "                    'Multi %': f'{multi_pct:.1f}',\n",
        "                    'Avg Labels': f'{avg_labels:.2f}',\n",
        "                    'Imbalance': f'{imbalance:.1f}:1'\n",
        "                })\n",
        "\n",
        "    # Print as formatted table\n",
        "    df_stats = pd.DataFrame(stats)\n",
        "    print(df_stats.to_string(index=False))\n",
        "\n",
        "    # Save as CSV for easy LaTeX import\n",
        "    csv_path = Path(Config.OUTPUT_DIR) / 'table_dataset_stats.csv'\n",
        "    df_stats.to_csv(csv_path, index=False)\n",
        "    print(f\"\\n✅ Table saved to: {csv_path}\")\n",
        "    print(\"Use \\\\csvreader or pandas-to-latex for LaTeX import\")\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"GENERATING PUBLICATION-QUALITY FIGURES FOR SEMEVAL-2026 PAPER\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Generate all figures\n",
        "    print(\"\\n📊 Generating Figure 1: Class Imbalance...\")\n",
        "    plot_imbalance_comparison()\n",
        "\n",
        "    print(\"\\n📊 Generating Figure 2: Label Co-occurrence...\")\n",
        "    plot_label_cooccurrence()\n",
        "\n",
        "    print(\"\\n📊 Generating Figure 3: Text Length Distribution...\")\n",
        "    plot_text_length_comparison()\n",
        "\n",
        "    print(\"\\n📊 Generating Figure 4: Multi-label Complexity...\")\n",
        "    plot_multilabel_complexity()\n",
        "\n",
        "    print(\"\\n📋 Generating Dataset Statistics Table...\")\n",
        "    generate_dataset_stats_table()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"✅ ALL FIGURES GENERATED\")\n",
        "    print(f\"📁 Location: {Config.OUTPUT_DIR}/\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\n💡 LaTeX Import Tips:\")\n",
        "    print(\"1. Use \\\\includegraphics[width=0.8\\\\textwidth]{fig1_class_imbalance.svg}\")\n",
        "    print(\"2. SVG files maintain quality at any scale\")\n",
        "    print(\"3. Reference figures in text: \\\\ref{fig:imbalance}\")\n",
        "    print(\"4. Use table_dataset_stats.csv for Table 1\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDcM0OH9c8y",
        "outputId": "c88d9bf5-f290-49a0-f1c0-3f488067547f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GENERATING PUBLICATION-QUALITY FIGURES FOR SEMEVAL-2026 PAPER\n",
            "================================================================================\n",
            "\n",
            "\n",
            "📊 Generating Figure 1: Class Imbalance...\n",
            "✅ Loaded eng_s2_train: 3222 samples\n",
            "✅ Loaded arb_s2_train: 3380 samples\n",
            "✅ Saved: paper_figures/fig1_class_imbalance.svg\n",
            "\n",
            "📊 Imbalance Statistics for Paper:\n",
            "English: 16.0:1 ratio\n",
            "Arabic: 2.8:1 ratio\n",
            "English most common: political (35.7%)\n",
            "English least common: gender/sexual (2.2%)\n",
            "\n",
            "📊 Generating Figure 2: Label Co-occurrence...\n",
            "✅ Loaded arb_s3_train: 3380 samples\n",
            "✅ Saved: paper_figures/fig2_label_correlation.svg\n",
            "\n",
            "📊 High Correlations for Paper:\n",
            "  stereotype ↔ extreme_language: r = 0.665\n",
            "  stereotype ↔ vilification: r = 0.664\n",
            "  vilification ↔ extreme_language: r = 0.650\n",
            "\n",
            "📊 Generating Figure 3: Text Length Distribution...\n",
            "✅ Loaded eng_s2_train: 3222 samples\n",
            "✅ Loaded arb_s2_train: 3380 samples\n",
            "✅ Saved: paper_figures/fig3_text_length.svg\n",
            "\n",
            "📊 Text Length Stats for Paper:\n",
            "English: mean=12.3, median=9.0, 95th=27\n",
            "Arabic: mean=16.7, median=16.0, 95th=31\n",
            "\n",
            "📊 Generating Figure 4: Multi-label Complexity...\n",
            "✅ Loaded eng_s2_train: 3222 samples\n",
            "✅ Loaded arb_s2_train: 3380 samples\n",
            "✅ Loaded eng_s3_train: 3222 samples\n",
            "✅ Loaded arb_s3_train: 3380 samples\n",
            "✅ Saved: paper_figures/fig4_multilabel_complexity.svg\n",
            "\n",
            "📋 Generating Dataset Statistics Table...\n",
            "\n",
            "================================================================================\n",
            "TABLE: DATASET STATISTICS (Copy to LaTeX)\n",
            "================================================================================\n",
            "\n",
            "✅ Loaded eng_s1_train: 3222 samples\n",
            "✅ Loaded arb_s1_train: 3380 samples\n",
            "✅ Loaded eng_s2_train: 3222 samples\n",
            "✅ Loaded arb_s2_train: 3380 samples\n",
            "✅ Loaded eng_s3_train: 3222 samples\n",
            "✅ Loaded arb_s3_train: 3380 samples\n",
            "Subtask Lang  Samples Avg Length Positive % Imbalance No Labels % Multi % Avg Labels\n",
            "     S1  ENG     3222       12.3       36.5         -         NaN     NaN        NaN\n",
            "     S1  ARB     3380       16.7       44.7         -         NaN     NaN        NaN\n",
            "     S2  ENG     3222       12.3        NaN    16.0:1        63.5    13.2       0.54\n",
            "     S2  ARB     3380       16.7        NaN     2.8:1        55.3    24.5       0.76\n",
            "     S3  ENG     3222       12.3        NaN     2.4:1        63.5    31.2       1.07\n",
            "     S3  ARB     3380       16.7        NaN     4.6:1        55.3    39.0       1.37\n",
            "\n",
            "✅ Table saved to: paper_figures/table_dataset_stats.csv\n",
            "Use \\csvreader or pandas-to-latex for LaTeX import\n",
            "\n",
            "================================================================================\n",
            "✅ ALL FIGURES GENERATED\n",
            "📁 Location: ./paper_figures/\n",
            "================================================================================\n",
            "\n",
            "💡 LaTeX Import Tips:\n",
            "1. Use \\includegraphics[width=0.8\\textwidth]{fig1_class_imbalance.svg}\n",
            "2. SVG files maintain quality at any scale\n",
            "3. Reference figures in text: \\ref{fig:imbalance}\n",
            "4. Use table_dataset_stats.csv for Table 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subtask 1"
      ],
      "metadata": {
        "id": "Nz0bJO4qn7Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SemEval 2026 Task 9 - Subtask 1: Polarization Detection\n",
        "Two-Stage Training Strategy (matching Subtasks 2 & 3)\n",
        "\n",
        "Stage 1: Find optimal thresholds on train/val split\n",
        "Stage 2: Train on ALL data, predict on test with optimized thresholds\n",
        "\n",
        "CHANGES FROM ORIGINAL:\n",
        "- Added two-stage training (was single-stage)\n",
        "- Separated threshold optimization from final training\n",
        "- No changes to model architecture, loss, or hyperparameters\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Paths\n",
        "    # TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/train/eng.csv\"\n",
        "    # TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/dev/eng.csv\"\n",
        "    # OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/pred_eng_two_stage.csv\"\n",
        "    TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/train/arb.csv\"\n",
        "    TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/dev/arb.csv\"\n",
        "    OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask1/pred_arb_two_stage.csv\"\n",
        "\n",
        "    # Model\n",
        "    # MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "    MODEL_NAME = \"UBC-NLP/MARBERTv2\"\n",
        "    MAX_LENGTH = 128\n",
        "\n",
        "    # Training - Two Stages\n",
        "    STAGE1_EPOCHS = 5  # For threshold finding\n",
        "    STAGE2_EPOCHS = 6  # For final model on all data\n",
        "    BATCH_SIZE = 32\n",
        "    EVAL_BATCH_SIZE = 64\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    EARLY_STOPPING_PATIENCE = 2\n",
        "    VAL_SIZE = 0.2\n",
        "\n",
        "    # Regularization\n",
        "    HIDDEN_DROPOUT = 0.1\n",
        "    ATTENTION_DROPOUT = 0.1\n",
        "\n",
        "    # Other\n",
        "    SEED = 40\n",
        "    USE_FP16 = True\n",
        "    TRAIN_FINAL_MODEL = True  # Set False to skip Stage 2 (for quick threshold tuning)\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(Config.SEED)\n",
        "\n",
        "# ==========================================\n",
        "# DATASET\n",
        "# ==========================================\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# ==========================================\n",
        "# METRICS\n",
        "# ==========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    f1_macro = f1_score(labels, preds, average='macro')\n",
        "    f1_binary = f1_score(labels, preds, pos_label=1)\n",
        "\n",
        "    return {\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_binary': f1_binary\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# TRAINER WITH CLASS WEIGHTS\n",
        "# ==========================================\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(model.device))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ==========================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def optimize_thresholds(val_probs, val_labels):\n",
        "    \"\"\"Scan thresholds to find optimal F1 Macro\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"THRESHOLD OPTIMIZATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    threshold_range = np.arange(0.3, 0.7, 0.01)\n",
        "    best_thresh = 0.5\n",
        "    best_f1 = 0\n",
        "    threshold_results = []\n",
        "\n",
        "    for thresh in threshold_range:\n",
        "        preds = (val_probs[:, 1] >= thresh).astype(int)\n",
        "        f1 = f1_score(val_labels, preds, average='macro')\n",
        "        threshold_results.append((thresh, f1))\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thresh = thresh\n",
        "\n",
        "    print(f\"Scanned {len(threshold_range)} thresholds from {threshold_range[0]:.2f} to {threshold_range[-1]:.2f}\")\n",
        "    print(f\"Optimal Threshold: {best_thresh:.3f}\")\n",
        "    print(f\"Validation F1 at Optimal Threshold: {best_f1:.4f}\")\n",
        "\n",
        "    # Show top 5\n",
        "    threshold_results.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(f\"\\nTop 5 thresholds:\")\n",
        "    for i, (thresh, f1) in enumerate(threshold_results[:5], 1):\n",
        "        print(f\"  {i}. Threshold {thresh:.3f}: F1 = {f1:.4f}\")\n",
        "\n",
        "    return best_thresh, best_f1\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 1: FIND OPTIMAL THRESHOLD\n",
        "# ==========================================\n",
        "def stage1_find_threshold(train_df):\n",
        "    \"\"\"Train on split data to find optimal threshold\"\"\"\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 1: Threshold Optimization\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Stratified split\n",
        "    train_split, val_split = train_test_split(\n",
        "        train_df,\n",
        "        test_size=Config.VAL_SIZE,\n",
        "        random_state=Config.SEED,\n",
        "        stratify=train_df['polarization']\n",
        "    )\n",
        "\n",
        "    print(f\"\\n📊 Split: {len(train_split)} train, {len(val_split)} val\")\n",
        "    print(f\"  Train - Class 0: {(train_split['polarization']==0).sum()}, Class 1: {(train_split['polarization']==1).sum()}\")\n",
        "    print(f\"  Val   - Class 0: {(val_split['polarization']==0).sum()}, Class 1: {(val_split['polarization']==1).sum()}\")\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(train_split['polarization']),\n",
        "        y=train_split['polarization']\n",
        "    )\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "    print(f\"\\nClass weights: [Class 0: {class_weights[0]:.3f}, Class 1: {class_weights[1]:.3f}]\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=2,\n",
        "        ignore_mismatched_sizes=True,\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = PolarizationDataset(\n",
        "        train_split['text'].tolist(),\n",
        "        train_split['polarization'].tolist(),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "    val_dataset = PolarizationDataset(\n",
        "        val_split['text'].tolist(),\n",
        "        val_split['polarization'].tolist(),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_s1_stage1\",\n",
        "        num_train_epochs=Config.STAGE1_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=1,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        greater_is_better=True,\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer = WeightedTrainer(\n",
        "        class_weights=class_weights_tensor,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=Config.EARLY_STOPPING_PATIENCE)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Stage 1...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\n✅ Stage 1 Results (0.5 threshold):\")\n",
        "    print(f\"  F1 Macro: {eval_metrics['eval_f1_macro']:.4f}\")\n",
        "    print(f\"  F1 Binary (Class 1): {eval_metrics['eval_f1_binary']:.4f}\")\n",
        "\n",
        "    # Get predictions for threshold optimization\n",
        "    val_predictions = trainer.predict(val_dataset)\n",
        "    val_probs = torch.nn.functional.softmax(\n",
        "        torch.tensor(val_predictions.predictions), dim=1\n",
        "    ).numpy()\n",
        "    val_labels = val_split['polarization'].values\n",
        "\n",
        "    # Optimize threshold\n",
        "    best_thresh, optimized_f1 = optimize_thresholds(val_probs, val_labels)\n",
        "\n",
        "    print(f\"\\n🎯 Optimized Validation F1: {optimized_f1:.4f}\")\n",
        "    print(f\"   Improvement over 0.5: +{optimized_f1 - eval_metrics['eval_f1_macro']:.4f}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_thresh, optimized_f1\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 2: TRAIN FINAL MODEL\n",
        "# ==========================================\n",
        "def stage2_train_final(train_df, test_df, best_thresh):\n",
        "    \"\"\"Train on ALL data and predict with optimized threshold\"\"\"\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 2: Final Model Training (All Data)\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Training on ALL {len(train_df)} samples\")\n",
        "    print(f\"  Class 0: {(train_df['polarization']==0).sum()}\")\n",
        "    print(f\"  Class 1: {(train_df['polarization']==1).sum()}\")\n",
        "\n",
        "    # Compute class weights on full dataset\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(train_df['polarization']),\n",
        "        y=train_df['polarization']\n",
        "    )\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=2,\n",
        "        ignore_mismatched_sizes=True,\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Dataset\n",
        "    train_dataset = PolarizationDataset(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df['polarization'].tolist(),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args - no validation\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_s1_stage2\",\n",
        "        num_train_epochs=Config.STAGE2_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=1,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",  # No validation, no checkpoints\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer = WeightedTrainer(\n",
        "        class_weights=class_weights_tensor,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Final Model...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predict on test\n",
        "    print(f\"\\n📊 Predicting on test set...\")\n",
        "    test_dataset = PolarizationDataset(\n",
        "        test_df['text'].tolist(),\n",
        "        [0] * len(test_df),  # Dummy labels\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    test_predictions = trainer.predict(test_dataset)\n",
        "    test_probs = torch.nn.functional.softmax(\n",
        "        torch.tensor(test_predictions.predictions), dim=1\n",
        "    ).numpy()\n",
        "\n",
        "    # Apply optimized threshold\n",
        "    final_preds = (test_probs[:, 1] >= best_thresh).astype(int)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# Subtask 1: Two-Stage Training\")\n",
        "    print(f\"# Stage 1: Find threshold on train/val split\")\n",
        "    print(f\"# Stage 2: Train on all data, predict with threshold\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Load\n",
        "    print(f\"\\n📂 Loading data...\")\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(Config.TEST_PATH)\n",
        "\n",
        "    print(f\"✅ Train: {len(train_df)} samples\")\n",
        "    print(f\"✅ Test: {len(test_df)} samples\")\n",
        "\n",
        "    # Stats\n",
        "    print(f\"\\n📊 Training Set:\")\n",
        "    print(f\"  Class 0: {(train_df['polarization']==0).sum()} ({100*(train_df['polarization']==0).mean():.1f}%)\")\n",
        "    print(f\"  Class 1: {(train_df['polarization']==1).sum()} ({100*(train_df['polarization']==1).mean():.1f}%)\")\n",
        "\n",
        "    word_lengths = train_df['text'].str.split().str.len()\n",
        "    print(f\"\\n  Text length: mean={word_lengths.mean():.1f}, median={word_lengths.median():.1f}, 95th={word_lengths.quantile(0.95):.0f}\")\n",
        "\n",
        "    # Stage 1: Find optimal threshold\n",
        "    best_thresh, val_f1 = stage1_find_threshold(train_df)\n",
        "\n",
        "    # Stage 2: Train final model\n",
        "    if Config.TRAIN_FINAL_MODEL:\n",
        "        final_preds = stage2_train_final(train_df, test_df, best_thresh)\n",
        "\n",
        "        # Save\n",
        "        print(f\"\\n💾 Saving predictions...\")\n",
        "        submission = pd.DataFrame({\n",
        "            'id': test_df['id'],\n",
        "            'polarization': final_preds\n",
        "        })\n",
        "        submission.to_csv(Config.OUTPUT_PATH, index=False)\n",
        "\n",
        "        print(f\"\\n✅ Saved: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "        # Stats\n",
        "        print(f\"\\n📊 Prediction Distribution:\")\n",
        "        unique, counts = np.unique(final_preds, return_counts=True)\n",
        "        for label, count in zip(unique, counts):\n",
        "            pct = 100 * count / len(final_preds)\n",
        "            train_pct = 100 * (train_df['polarization'] == label).mean()\n",
        "            print(f\"  Class {label}: {count} ({pct:.1f}%) | Train: {train_pct:.1f}%\")\n",
        "    else:\n",
        "        print(f\"\\n⭐ Skipping Stage 2 (TRAIN_FINAL_MODEL=False)\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✅ COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nValidation F1: {val_f1:.4f}\")\n",
        "    print(f\"Optimal Threshold: {best_thresh:.3f}\")\n",
        "\n",
        "    return best_thresh, val_f1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    threshold, f1 = main()\n",
        "    print(\"\\n✨ Done! Submit the CSV file to the competition.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4CDpR49koTWG",
        "outputId": "ca01760f-4798-48f0-b73a-1e9319e4ef04",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################################################\n",
            "# Subtask 1: Two-Stage Training\n",
            "# Stage 1: Find threshold on train/val split\n",
            "# Stage 2: Train on all data, predict with threshold\n",
            "############################################################\n",
            "\n",
            "📂 Loading data...\n",
            "✅ Train: 3380 samples\n",
            "✅ Test: 169 samples\n",
            "\n",
            "📊 Training Set:\n",
            "  Class 0: 1868 (55.3%)\n",
            "  Class 1: 1512 (44.7%)\n",
            "\n",
            "  Text length: mean=16.7, median=16.0, 95th=31\n",
            "\n",
            "############################################################\n",
            "# STAGE 1: Threshold Optimization\n",
            "############################################################\n",
            "\n",
            "📊 Split: 2704 train, 676 val\n",
            "  Train - Class 0: 1494, Class 1: 1210\n",
            "  Val   - Class 0: 374, Class 1: 302\n",
            "\n",
            "Class weights: [Class 0: 0.905, Class 1: 1.117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Stage 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [425/425 03:11, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.620100</td>\n",
              "      <td>0.444563</td>\n",
              "      <td>0.789343</td>\n",
              "      <td>0.778125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.301200</td>\n",
              "      <td>0.451734</td>\n",
              "      <td>0.791416</td>\n",
              "      <td>0.790490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.542748</td>\n",
              "      <td>0.806141</td>\n",
              "      <td>0.802413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.100900</td>\n",
              "      <td>0.635459</td>\n",
              "      <td>0.810266</td>\n",
              "      <td>0.791461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.073700</td>\n",
              "      <td>0.674629</td>\n",
              "      <td>0.815390</td>\n",
              "      <td>0.800643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stage 1 Results (0.5 threshold):\n",
            "  F1 Macro: 0.8154\n",
            "  F1 Binary (Class 1): 0.8006\n",
            "\n",
            "============================================================\n",
            "THRESHOLD OPTIMIZATION\n",
            "============================================================\n",
            "Scanned 40 thresholds from 0.30 to 0.69\n",
            "Optimal Threshold: 0.420\n",
            "Validation F1 at Optimal Threshold: 0.8185\n",
            "\n",
            "Top 5 thresholds:\n",
            "  1. Threshold 0.420: F1 = 0.8185\n",
            "  2. Threshold 0.430: F1 = 0.8185\n",
            "  3. Threshold 0.440: F1 = 0.8185\n",
            "  4. Threshold 0.450: F1 = 0.8185\n",
            "  5. Threshold 0.460: F1 = 0.8185\n",
            "\n",
            "🎯 Optimized Validation F1: 0.8185\n",
            "   Improvement over 0.5: +0.0031\n",
            "\n",
            "############################################################\n",
            "# STAGE 2: Final Model Training (All Data)\n",
            "############################################################\n",
            "\n",
            "📊 Training on ALL 3380 samples\n",
            "  Class 0: 1868\n",
            "  Class 1: 1512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Final Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [636/636 01:17, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.650900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.345400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.315600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.224300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.183800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.058800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Predicting on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving predictions...\n",
            "\n",
            "✅ Saved: /content/gdrive/MyDrive/SemEval/dev_phase/subtask1/pred_arb_two_stage.csv\n",
            "\n",
            "📊 Prediction Distribution:\n",
            "  Class 0: 98 (58.0%) | Train: 55.3%\n",
            "  Class 1: 71 (42.0%) | Train: 44.7%\n",
            "\n",
            "============================================================\n",
            "✅ COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Validation F1: 0.8185\n",
            "Optimal Threshold: 0.420\n",
            "\n",
            "✨ Done! Submit the CSV file to the competition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subtask 2"
      ],
      "metadata": {
        "id": "23whIFspsdOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## english"
      ],
      "metadata": {
        "id": "dmfGYkLq8hI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "English Subtask 2: Two-Stage Training\n",
        "Stage 1: Find thresholds on train/val split\n",
        "Stage 2: Train on ALL data, predict on test\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Paths\n",
        "    TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/train/eng.csv\"\n",
        "    TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/dev/eng.csv\"\n",
        "    OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/pred_eng_two_stage.csv\"\n",
        "\n",
        "    # Labels\n",
        "    LABEL_COLUMNS = ['political', 'racial/ethnic', 'religious', 'gender/sexual', 'other']\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "    MAX_LENGTH = 64\n",
        "\n",
        "    # Training\n",
        "    STAGE1_EPOCHS = 5  # For threshold finding\n",
        "    STAGE2_EPOCHS = 6  # For final model\n",
        "    BATCH_SIZE = 16\n",
        "    EVAL_BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    VAL_SIZE = 0.2\n",
        "\n",
        "    # Regularization\n",
        "    HIDDEN_DROPOUT = 0.1\n",
        "    ATTENTION_DROPOUT = 0.1\n",
        "\n",
        "    # Focal Loss\n",
        "    USE_FOCAL_LOSS = True\n",
        "    FOCAL_ALPHA = 0.25\n",
        "    FOCAL_GAMMA = 2.0  # Higher for English's extreme imbalance\n",
        "\n",
        "    # Other\n",
        "    SEED = 42\n",
        "    USE_FP16 = True\n",
        "    TRAIN_FINAL_MODEL = True\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(Config.SEED)\n",
        "\n",
        "# ==========================================\n",
        "# FOCAL LOSS\n",
        "# ==========================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# ==========================================\n",
        "# DATASET\n",
        "# ==========================================\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ==========================================\n",
        "# METRICS\n",
        "# ==========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-predictions))\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1_per_class = f1_score(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "    metrics = {'f1_macro': f1_macro}\n",
        "    for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "        metrics[f'f1_{col}'] = f1_per_class[i]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ==========================================\n",
        "# TRAINER\n",
        "# ==========================================\n",
        "class FocalLossTrainer(Trainer):\n",
        "    def __init__(self, focal_loss_fn, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.focal_loss_fn = focal_loss_fn\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.focal_loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ==========================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def optimize_thresholds(val_probs, val_labels, label_names):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"THRESHOLD OPTIMIZATION (Class-Aware)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    best_thresholds = []\n",
        "    class_frequencies = val_labels.sum(axis=0) / len(val_labels)\n",
        "\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        freq = class_frequencies[i]\n",
        "        best_thresh = 0.5\n",
        "        best_f1 = 0\n",
        "\n",
        "        # Class-specific ranges for extreme English imbalance\n",
        "        if freq < 0.05:  # Very rare\n",
        "            threshold_range = np.arange(0.05, 0.7, 0.05)\n",
        "        elif freq < 0.15:  # Rare\n",
        "            threshold_range = np.arange(0.1, 0.75, 0.05)\n",
        "        else:  # Common\n",
        "            threshold_range = np.arange(0.15, 0.8, 0.05)\n",
        "\n",
        "        for thresh in threshold_range:\n",
        "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
        "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        best_thresholds.append(best_thresh)\n",
        "        print(f\"{label_name:20s}: threshold={best_thresh:.2f}, F1={best_f1:.4f} \"\n",
        "              f\"(freq={100*freq:.1f}%)\")\n",
        "\n",
        "    return np.array(best_thresholds)\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 1: FIND THRESHOLDS\n",
        "# ==========================================\n",
        "def stage1_find_thresholds(train_df):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 1: Threshold Optimization\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Split\n",
        "    has_label = (train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).astype(int)\n",
        "    train_data, val_data = train_test_split(\n",
        "        train_df,\n",
        "        test_size=Config.VAL_SIZE,\n",
        "        random_state=Config.SEED,\n",
        "        stratify=has_label\n",
        "    )\n",
        "\n",
        "    print(f\"\\n📊 Split: {len(train_data)} train, {len(val_data)} val\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_data['text'].tolist(),\n",
        "        train_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "    val_dataset = MultiLabelDataset(\n",
        "        val_data['text'].tolist(),\n",
        "        val_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_eng_s2_stage1\",\n",
        "        num_train_epochs=Config.STAGE1_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Stage 1...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\n✅ Stage 1 Results:\")\n",
        "    print(f\"  F1 Macro: {eval_metrics['eval_f1_macro']:.4f}\")\n",
        "\n",
        "    # Get predictions\n",
        "    val_predictions = trainer.predict(val_dataset)\n",
        "    val_logits = val_predictions.predictions\n",
        "    val_probs = 1 / (1 + np.exp(-val_logits))\n",
        "    val_labels = val_data[Config.LABEL_COLUMNS].values\n",
        "\n",
        "    # Optimize thresholds\n",
        "    best_thresholds = optimize_thresholds(val_probs, val_labels, Config.LABEL_COLUMNS)\n",
        "\n",
        "    # Calculate optimized F1\n",
        "    val_preds_optimized = np.zeros_like(val_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        val_preds_optimized[:, i] = (val_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    optimized_f1 = f1_score(val_labels, val_preds_optimized, average='macro', zero_division=0)\n",
        "    print(f\"\\n🎯 Optimized Validation F1: {optimized_f1:.4f}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 2: FINAL MODEL\n",
        "# ==========================================\n",
        "def stage2_train_final(train_df, test_df, best_thresholds):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 2: Final Model Training (All Data)\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Training on ALL {len(train_df)} samples\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Dataset\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_eng_s2_stage2\",\n",
        "        num_train_epochs=Config.STAGE2_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Final Model...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predict\n",
        "    print(f\"\\n📊 Predicting on test set...\")\n",
        "    test_dataset = MultiLabelDataset(\n",
        "        test_df['text'].tolist(),\n",
        "        np.zeros((len(test_df), len(Config.LABEL_COLUMNS))),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    test_predictions = trainer.predict(test_dataset)\n",
        "    test_logits = test_predictions.predictions\n",
        "    test_probs = 1 / (1 + np.exp(-test_logits))\n",
        "\n",
        "    # Apply thresholds\n",
        "    final_preds = np.zeros_like(test_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        final_preds[:, i] = (test_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# English Subtask 2: Two-Stage Training\")\n",
        "    print(f\"# Focal Loss γ={Config.FOCAL_GAMMA} for 16:1 imbalance\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Load\n",
        "    print(f\"\\n📂 Loading data...\")\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(Config.TEST_PATH)\n",
        "\n",
        "    # Clean\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].fillna(0).astype(int)\n",
        "\n",
        "    print(f\"✅ Train: {len(train_df)} samples\")\n",
        "    print(f\"✅ Test: {len(test_df)} samples (blind)\")\n",
        "\n",
        "    # Stats\n",
        "    print(f\"\\n📊 Label Distribution:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        count = train_df[col].sum()\n",
        "        pct = 100 * train_df[col].mean()\n",
        "        print(f\"  {col:20s}: {count:4d} ({pct:5.2f}%)\")\n",
        "\n",
        "    # Stage 1\n",
        "    best_thresholds = stage1_find_thresholds(train_df)\n",
        "\n",
        "    # Stage 2\n",
        "    if Config.TRAIN_FINAL_MODEL:\n",
        "        final_preds = stage2_train_final(train_df, test_df, best_thresholds)\n",
        "\n",
        "        # Save\n",
        "        print(f\"\\n💾 Saving predictions...\")\n",
        "        submission = pd.DataFrame(final_preds, columns=Config.LABEL_COLUMNS)\n",
        "        submission.insert(0, 'id', test_df['id'])\n",
        "        submission.to_csv(Config.OUTPUT_PATH, index=False)\n",
        "\n",
        "        print(f\"\\n✅ Saved: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "        # Stats\n",
        "        print(f\"\\n📊 Prediction Distribution:\")\n",
        "        for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "            count = final_preds[:, i].sum()\n",
        "            pct = 100 * count / len(final_preds)\n",
        "            train_pct = 100 * train_df[col].mean()\n",
        "            print(f\"  {col:20s}: {count:3d} ({pct:5.2f}%) | Train: {train_pct:5.2f}%\")\n",
        "    else:\n",
        "        print(f\"\\n⭐ Skipping Stage 2\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✅ COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thresholds = main()\n",
        "    print(\"\\n✨ Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7cc34106090c4f9c945c88e87de26a1e",
            "0ea5e6db85ca41f6abe40667c2e9470b",
            "1d7c3b8beac8473399b3e99d164bbf47",
            "4c9f424673124f10b0341ce409b25cf0",
            "9011e4c36c444a658abf7edd3f419ad8",
            "7aa8bbc9f03c44a2ab99e3a2c3a15fe2",
            "d9d84409a86842f2b89995727d0d584b",
            "9c980014bbe44fada168417484efc7d9",
            "ab791613cbf24089a0423e7a5d0b7579",
            "002ea57e97de409eb51e663f43dfbeac",
            "79db9f1f6779402480e332289da596e3",
            "fd9309908e2245eeafb4161f47d38b30",
            "eb2ed6dd0ae945f5b625184de9b56bae",
            "73763438bc7e483c9a5a161d48d2a70d",
            "d0cb8fbc44de428faf0e59ce754ef1d3",
            "d3a1212bd4c44c51baf99e8f421925f2",
            "50ba45e5bbb04e18bab80635eb58f578",
            "a23c7c256a624a2d920a8525398f71c9",
            "c7aa4d554fd8444aa9522694b8899ec5",
            "1abddcff37164146bebd508a134f607d",
            "32ff491bb7c34b77af8828fd0539268a",
            "7438aecd3650463a8595d57ac582d562",
            "3cf5e361817d407fa6e85603d9c618f7",
            "3122c709580a4e878fce01ee1efe807d",
            "0815552710a04da79a63d7c8dfd9448b",
            "d8235d0b451641ddaf83c2830e75e6a2",
            "3b231d2bd1074026b84ca08d357d7254",
            "0742f20de550411c98cd1be54be54525",
            "3c203a94e3f840dc8cd756bd407225ef",
            "a6562497ba58479aa393f08e18cc6f29",
            "c6d4e925126a4af8a18c83bfe2645f9b",
            "82ba4e3d06104ae58d48283fc97c8fc3",
            "b9ce5841b8bb4c7e99d33bc5c498ffdb",
            "d23b65fa7a434322be261a11c5d0c5cd",
            "b0b4a57b64c347a1a565b5be9a3f07c2",
            "0445a1dce58744db843e6cfd543c30ea",
            "6bf2349dd77e49c7bc2fc981887c740b",
            "d94e1042838543a7af398adf5e10f72d",
            "3e7af778528f412f8fc84db1222a17a3",
            "72737253868c4c8588f211f5406cb433",
            "aafbae3e25054a459f4440e718a6b32e",
            "487930aa3c71491291f4b828697e501a",
            "dd8b40fbb63e47c48a568c8cf7080a82",
            "a7d953413e004138a53fc85763ae1d04",
            "b194b84ef8fd41fa85449d588201d8ca",
            "7b157a6325984187a84847bdbbd7bfc7",
            "21934033c3d742329b797b0c50c88ce1",
            "2c7e1a6593b444829dbc8e8941713d36",
            "ff683b99f6ee447e9669ccf770c66052",
            "e8167a5e7be9429cb9c48202ed76ee82",
            "3223c2faa14e449d8dfa9b0768762fb1",
            "976ade26cbc44122b0335c83f7290c2c",
            "66a0837bb1084e2aaa2ad22cd3bfc94a",
            "9223baa4f81c41ffafc9f37be6b48a90",
            "cfc9ba67c3e34ef180a7a76da9b83b52"
          ]
        },
        "id": "2NkfB6cZt9vc",
        "outputId": "eb7b13a9-807d-4a48-d72a-c6f3c92efb61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################################################\n",
            "# English Subtask 2: Two-Stage Training\n",
            "# Focal Loss γ=2.2 for 16:1 imbalance\n",
            "############################################################\n",
            "\n",
            "📂 Loading data...\n",
            "✅ Train: 3222 samples\n",
            "✅ Test: 160 samples (blind)\n",
            "\n",
            "📊 Label Distribution:\n",
            "  political           : 1150 (35.69%)\n",
            "  racial/ethnic       :  281 ( 8.72%)\n",
            "  religious           :  112 ( 3.48%)\n",
            "  gender/sexual       :   72 ( 2.23%)\n",
            "  other               :  126 ( 3.91%)\n",
            "\n",
            "############################################################\n",
            "# STAGE 1: Threshold Optimization\n",
            "############################################################\n",
            "\n",
            "📊 Split: 2577 train, 645 val\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cc34106090c4f9c945c88e87de26a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd9309908e2245eeafb4161f47d38b30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cf5e361817d407fa6e85603d9c618f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d23b65fa7a434322be261a11c5d0c5cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b194b84ef8fd41fa85449d588201d8ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Stage 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [405/405 03:53, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Political</th>\n",
              "      <th>F1 Racial/ethnic</th>\n",
              "      <th>F1 Religious</th>\n",
              "      <th>F1 Gender/sexual</th>\n",
              "      <th>F1 Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>0.014687</td>\n",
              "      <td>0.118182</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.012527</td>\n",
              "      <td>0.148659</td>\n",
              "      <td>0.743295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>0.012539</td>\n",
              "      <td>0.159862</td>\n",
              "      <td>0.738703</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.014068</td>\n",
              "      <td>0.187009</td>\n",
              "      <td>0.735043</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.015502</td>\n",
              "      <td>0.195737</td>\n",
              "      <td>0.712018</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stage 1 Results:\n",
            "  F1 Macro: 0.1957\n",
            "\n",
            "============================================================\n",
            "THRESHOLD OPTIMIZATION (Class-Aware)\n",
            "============================================================\n",
            "political           : threshold=0.35, F1=0.7604 (freq=35.7%)\n",
            "racial/ethnic       : threshold=0.25, F1=0.4615 (freq=9.6%)\n",
            "religious           : threshold=0.30, F1=0.3000 (freq=4.0%)\n",
            "gender/sexual       : threshold=0.25, F1=0.2222 (freq=3.1%)\n",
            "other               : threshold=0.35, F1=0.1772 (freq=3.4%)\n",
            "\n",
            "🎯 Optimized Validation F1: 0.3843\n",
            "\n",
            "############################################################\n",
            "# STAGE 2: Final Model Training (All Data)\n",
            "############################################################\n",
            "\n",
            "📊 Training on ALL 3222 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Final Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 02:21, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.014600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.010100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.006500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.005600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.005200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Predicting on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving predictions...\n",
            "\n",
            "✅ Saved: /content/gdrive/MyDrive/SemEval/dev_phase/subtask2/pred_eng_two_stage.csv\n",
            "\n",
            "📊 Prediction Distribution:\n",
            "  political           :  63 (39.38%) | Train: 35.69%\n",
            "  racial/ethnic       :  21 (13.12%) | Train:  8.72%\n",
            "  religious           :   8 ( 5.00%) | Train:  3.48%\n",
            "  gender/sexual       :  14 ( 8.75%) | Train:  2.23%\n",
            "  other               :   5 ( 3.12%) | Train:  3.91%\n",
            "\n",
            "============================================================\n",
            "✅ COMPLETE!\n",
            "============================================================\n",
            "\n",
            "✨ Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## arabic"
      ],
      "metadata": {
        "id": "duPm5iX08kVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FIXED: Arabic Subtask 2 with MARBERT\n",
        "Adjusted for Arabic data characteristics:\n",
        "- Longer texts (16.7 words avg, 31 words 95th percentile)\n",
        "- Better class balance (2.8:1 vs 16:1)\n",
        "- Dev set has NO labels (blind test set)\n",
        "\n",
        "CRITICAL CHANGE: Since dev set has no labels, we:\n",
        "1. Split training data into train/val (80/20)\n",
        "2. Optimize thresholds on our validation split\n",
        "3. Train final model on ALL training data\n",
        "4. Predict on blind test set\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION - OPTIMIZED FOR ARABIC\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Paths\n",
        "\n",
        "    TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/train/arb.csv\"\n",
        "    TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/dev/arb.csv\"\n",
        "    OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask2/pred_arb_marbert.csv\"\n",
        "\n",
        "    # Labels\n",
        "    LABEL_COLUMNS = ['political', 'racial/ethnic', 'religious', 'gender/sexual', 'other']\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"UBC-NLP/MARBERT\"\n",
        "    MAX_LENGTH = 96  # INCREASED from 64 (Arabic: 31 words at 95th percentile)\n",
        "\n",
        "    # Training - Two stages\n",
        "    STAGE1_EPOCHS = 5  # For finding thresholds\n",
        "    STAGE2_EPOCHS = 6  # Final model on all data\n",
        "    BATCH_SIZE = 16\n",
        "    EVAL_BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    VAL_SIZE = 0.2\n",
        "\n",
        "    # Regularization - REDUCED (better balance, less overfitting risk)\n",
        "    HIDDEN_DROPOUT = 0.1  # REDUCED from 0.15\n",
        "    ATTENTION_DROPOUT = 0.1\n",
        "\n",
        "    # Loss - ADJUSTED for better balance\n",
        "    USE_FOCAL_LOSS = True\n",
        "    FOCAL_ALPHA = 0.25\n",
        "    FOCAL_GAMMA = 1.5  # REDUCED from 2.0 (less extreme imbalance)\n",
        "\n",
        "    # Other\n",
        "    SEED = 42\n",
        "    USE_FP16 = True\n",
        "    TRAIN_FINAL_MODEL = True  # Set False for quick threshold tuning only\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(Config.SEED)\n",
        "\n",
        "# ==========================================\n",
        "# FOCAL LOSS\n",
        "# ==========================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# ==========================================\n",
        "# DATASET\n",
        "# ==========================================\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=96):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ==========================================\n",
        "# METRICS\n",
        "# ==========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-predictions))\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1_per_class = f1_score(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "    metrics = {'f1_macro': f1_macro}\n",
        "    for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "        metrics[f'f1_{col}'] = f1_per_class[i]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ==========================================\n",
        "# TRAINER\n",
        "# ==========================================\n",
        "class FocalLossTrainer(Trainer):\n",
        "    def __init__(self, focal_loss_fn, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.focal_loss_fn = focal_loss_fn\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.focal_loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ==========================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def optimize_thresholds(val_probs, val_labels, label_names):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"THRESHOLD OPTIMIZATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    best_thresholds = []\n",
        "\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        best_thresh = 0.5\n",
        "        best_f1 = 0\n",
        "\n",
        "        # Wider range for Arabic (better balance)\n",
        "        for thresh in np.arange(0.15, 0.75, 0.05):\n",
        "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
        "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        best_thresholds.append(best_thresh)\n",
        "        print(f\"{label_name:20s}: threshold={best_thresh:.2f}, F1={best_f1:.4f}\")\n",
        "\n",
        "    return np.array(best_thresholds)\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 1: FIND OPTIMAL THRESHOLDS\n",
        "# ==========================================\n",
        "def stage1_find_thresholds(train_df):\n",
        "    \"\"\"Train on split data to find optimal thresholds\"\"\"\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 1: Threshold Optimization\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Split for threshold tuning\n",
        "    has_label = (train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).astype(int)\n",
        "    train_data, val_data = train_test_split(\n",
        "        train_df,\n",
        "        test_size=Config.VAL_SIZE,\n",
        "        random_state=Config.SEED,\n",
        "        stratify=has_label\n",
        "    )\n",
        "\n",
        "    print(f\"\\n📊 Split: {len(train_data)} train, {len(val_data)} val\")\n",
        "\n",
        "    # Initialize model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_data['text'].tolist(),\n",
        "        train_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "    val_dataset = MultiLabelDataset(\n",
        "        val_data['text'].tolist(),\n",
        "        val_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_stage1\",\n",
        "        num_train_epochs=Config.STAGE1_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Stage 1...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\n✅ Stage 1 Results:\")\n",
        "    print(f\"  F1 Macro: {eval_metrics['eval_f1_macro']:.4f}\")\n",
        "\n",
        "    # Get validation predictions\n",
        "    val_predictions = trainer.predict(val_dataset)\n",
        "    val_logits = val_predictions.predictions\n",
        "    val_probs = 1 / (1 + np.exp(-val_logits))\n",
        "    val_labels = val_data[Config.LABEL_COLUMNS].values\n",
        "\n",
        "    # Optimize thresholds\n",
        "    best_thresholds = optimize_thresholds(val_probs, val_labels, Config.LABEL_COLUMNS)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 2: TRAIN FINAL MODEL ON ALL DATA\n",
        "# ==========================================\n",
        "def stage2_train_final(train_df, test_df, best_thresholds):\n",
        "    \"\"\"Train on ALL training data and predict on test\"\"\"\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 2: Final Model Training (All Data)\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Training on ALL {len(train_df)} samples\")\n",
        "\n",
        "    # Initialize model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training arguments - no validation\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_stage2\",\n",
        "        num_train_epochs=Config.STAGE2_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",  # No validation, no saving\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Final Model...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predict on test\n",
        "    print(f\"\\n📊 Predicting on test set...\")\n",
        "    test_dataset = MultiLabelDataset(\n",
        "        test_df['text'].tolist(),\n",
        "        np.zeros((len(test_df), len(Config.LABEL_COLUMNS))),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    test_predictions = trainer.predict(test_dataset)\n",
        "    test_logits = test_predictions.predictions\n",
        "    test_probs = 1 / (1 + np.exp(-test_logits))\n",
        "\n",
        "    # Apply optimized thresholds\n",
        "    final_preds = np.zeros_like(test_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        final_preds[:, i] = (test_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# Arabic Subtask 2: Two-Stage Training\")\n",
        "    print(f\"# Stage 1: Find thresholds on train/val split\")\n",
        "    print(f\"# Stage 2: Train on all data, predict on test\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"\\n📂 Loading data...\")\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(Config.TEST_PATH)\n",
        "\n",
        "    # Clean labels\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].fillna(0).astype(int)\n",
        "\n",
        "    print(f\"✅ Train: {len(train_df)} samples\")\n",
        "    print(f\"✅ Test: {len(test_df)} samples (blind - no labels)\")\n",
        "\n",
        "    # Dataset statistics\n",
        "    print(f\"\\n📊 Arabic Dataset Characteristics:\")\n",
        "    print(f\"  Text length (mean): {train_df['text'].str.split().str.len().mean():.1f} words\")\n",
        "    print(f\"  Text length (95th): {train_df['text'].str.split().str.len().quantile(0.95):.0f} words\")\n",
        "    print(f\"  Samples with labels: {(train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).sum()} ({100*(train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).mean():.1f}%)\")\n",
        "    print(f\"  Multi-label samples: {(train_df[Config.LABEL_COLUMNS].sum(axis=1) > 1).sum()} ({100*(train_df[Config.LABEL_COLUMNS].sum(axis=1) > 1).mean():.1f}%)\")\n",
        "\n",
        "    print(f\"\\n🏷️  Label Distribution:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        count = train_df[col].sum()\n",
        "        pct = 100 * train_df[col].mean()\n",
        "        print(f\"  {col:20s}: {count:4d} ({pct:5.2f}%)\")\n",
        "\n",
        "    # Stage 1: Find optimal thresholds\n",
        "    best_thresholds = stage1_find_thresholds(train_df)\n",
        "\n",
        "    # Stage 2: Train final model (optional, can skip for quick testing)\n",
        "    if Config.TRAIN_FINAL_MODEL:\n",
        "        final_preds = stage2_train_final(train_df, test_df, best_thresholds)\n",
        "\n",
        "        # Save predictions\n",
        "        print(f\"\\n💾 Saving predictions...\")\n",
        "        submission = pd.DataFrame(final_preds, columns=Config.LABEL_COLUMNS)\n",
        "        submission.insert(0, 'id', test_df['id'])\n",
        "        submission.to_csv(Config.OUTPUT_PATH, index=False)\n",
        "\n",
        "        print(f\"\\n✅ Predictions saved to: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "        # Prediction stats\n",
        "        print(f\"\\n📊 Prediction Distribution:\")\n",
        "        for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "            count = final_preds[:, i].sum()\n",
        "            pct = 100 * count / len(final_preds)\n",
        "            print(f\"  {col:20s}: {count:3d} ({pct:5.2f}%)\")\n",
        "    else:\n",
        "        print(f\"\\n⏭️  Skipping Stage 2 (TRAIN_FINAL_MODEL=False)\")\n",
        "        print(f\"   Set TRAIN_FINAL_MODEL=True to generate final predictions\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✅ COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thresholds = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "292148b7c727429db450cb69dc6640dd",
            "bc648df701294de59cded1bd2a3fe0e8",
            "6d5261c65c1a473abf5b66853c045ea0",
            "a50b27c767344acebba981be5f4cd6a5",
            "1aab3b21064549cab950cb45fda3e84b",
            "3faa5e63dcf3471995c8f0d8ad3d2692",
            "26687174d77e4d33af636fe6f0997c1b",
            "4d872327781a41c5ae0c319c0d598e07",
            "5c6e7b108e11414f98ae5c4307892c57",
            "9d0f5647a85941d288ba1340b9ad7a98",
            "0f82e3b9009a4ce2ae4ffcb726ec16fd",
            "5d5fc5f459e143f482196c86c80819b8",
            "ea628eb78d944eac93b3380dd8e95e5d",
            "a011246467614d61b1410f4c7d716f14",
            "95bec357802a4ad08f172a12226ced97",
            "5caa88c44f3f416c85f3f6609b059dd2",
            "b8e50c032cf047b89804c8e35dfecb05",
            "b11fffba039b4f74aceeaefc6210452c",
            "2dc0db8e04a14562ab387c416830661d",
            "3616e535424243c0b3d4efad60932248",
            "b5182e0daf084a089238ca73c2e32c7f",
            "7ffa39ac89ac4b559054fbab4403d22e"
          ]
        },
        "id": "l2EYKDMP8muI",
        "outputId": "a722f1dc-9692-4525-b34f-3a7dedbbf557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################################################\n",
            "# Arabic Subtask 2: Two-Stage Training\n",
            "# Stage 1: Find thresholds on train/val split\n",
            "# Stage 2: Train on all data, predict on test\n",
            "############################################################\n",
            "\n",
            "📂 Loading data...\n",
            "✅ Train: 3380 samples\n",
            "✅ Test: 169 samples (blind - no labels)\n",
            "\n",
            "📊 Arabic Dataset Characteristics:\n",
            "  Text length (mean): 16.7 words\n",
            "  Text length (95th): 31 words\n",
            "  Samples with labels: 1512 (44.7%)\n",
            "  Multi-label samples: 828 (24.5%)\n",
            "\n",
            "🏷️  Label Distribution:\n",
            "  political           :  780 (23.08%)\n",
            "  racial/ethnic       :  583 (17.25%)\n",
            "  religious           :  283 ( 8.37%)\n",
            "  gender/sexual       :  369 (10.92%)\n",
            "  other               :  565 (16.72%)\n",
            "\n",
            "############################################################\n",
            "# STAGE 1: Threshold Optimization\n",
            "############################################################\n",
            "\n",
            "📊 Split: 2704 train, 676 val\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "292148b7c727429db450cb69dc6640dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d5fc5f459e143f482196c86c80819b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Stage 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [425/425 02:52, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Political</th>\n",
              "      <th>F1 Racial/ethnic</th>\n",
              "      <th>F1 Religious</th>\n",
              "      <th>F1 Gender/sexual</th>\n",
              "      <th>F1 Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.043100</td>\n",
              "      <td>0.025721</td>\n",
              "      <td>0.455191</td>\n",
              "      <td>0.695035</td>\n",
              "      <td>0.537736</td>\n",
              "      <td>0.441860</td>\n",
              "      <td>0.329897</td>\n",
              "      <td>0.271429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.021600</td>\n",
              "      <td>0.023479</td>\n",
              "      <td>0.610697</td>\n",
              "      <td>0.704050</td>\n",
              "      <td>0.626728</td>\n",
              "      <td>0.641509</td>\n",
              "      <td>0.573427</td>\n",
              "      <td>0.507772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.025719</td>\n",
              "      <td>0.566122</td>\n",
              "      <td>0.713805</td>\n",
              "      <td>0.629108</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.475138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.028881</td>\n",
              "      <td>0.575712</td>\n",
              "      <td>0.711246</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.556701</td>\n",
              "      <td>0.524590</td>\n",
              "      <td>0.419355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>0.029460</td>\n",
              "      <td>0.592476</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.669643</td>\n",
              "      <td>0.563107</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.456522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stage 1 Results:\n",
            "  F1 Macro: 0.6107\n",
            "\n",
            "============================================================\n",
            "THRESHOLD OPTIMIZATION\n",
            "============================================================\n",
            "political           : threshold=0.45, F1=0.7225\n",
            "racial/ethnic       : threshold=0.40, F1=0.6692\n",
            "religious           : threshold=0.50, F1=0.6415\n",
            "gender/sexual       : threshold=0.45, F1=0.6087\n",
            "other               : threshold=0.45, F1=0.5462\n",
            "\n",
            "############################################################\n",
            "# STAGE 2: Final Model Training (All Data)\n",
            "############################################################\n",
            "\n",
            "📊 Training on ALL 3380 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Final Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [636/636 01:39, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.028900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.021800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.021400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.014800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Predicting on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving predictions...\n",
            "\n",
            "✅ Predictions saved to: /content/gdrive/MyDrive/SemEval/dev_phase/subtask2/pred_arb_marbert.csv\n",
            "\n",
            "📊 Prediction Distribution:\n",
            "  political           :  38 (22.49%)\n",
            "  racial/ethnic       :  32 (18.93%)\n",
            "  religious           :  11 ( 6.51%)\n",
            "  gender/sexual       :  15 ( 8.88%)\n",
            "  other               :  25 (14.79%)\n",
            "\n",
            "============================================================\n",
            "✅ COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subtask 3"
      ],
      "metadata": {
        "id": "Nhc58xXgluWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## english"
      ],
      "metadata": {
        "id": "y-rKCx6JAOPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "English Subtask 3: Two-Stage Training (matching Arabic approach)\n",
        "Stage 1: Find thresholds on train/val split\n",
        "Stage 2: Train on ALL data, predict on test\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Paths\n",
        "    TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/train/eng.csv\"\n",
        "    TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/dev/eng.csv\"\n",
        "    OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/pred_eng_two_stage.csv\"\n",
        "\n",
        "    # Labels\n",
        "    LABEL_COLUMNS = ['stereotype', 'vilification', 'dehumanization',\n",
        "                     'extreme_language', 'lack_of_empathy', 'invalidation']\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "    MAX_LENGTH = 128\n",
        "\n",
        "    # Training\n",
        "    STAGE1_EPOCHS = 5  # For threshold finding\n",
        "    STAGE2_EPOCHS = 6  # For final model\n",
        "    BATCH_SIZE = 16\n",
        "    EVAL_BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    VAL_SIZE = 0.2\n",
        "\n",
        "    # Regularization\n",
        "    HIDDEN_DROPOUT = 0.1\n",
        "    ATTENTION_DROPOUT = 0.1\n",
        "\n",
        "    # Other\n",
        "    SEED = 42\n",
        "    USE_FP16 = True\n",
        "    TRAIN_FINAL_MODEL = True\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(Config.SEED)\n",
        "\n",
        "# ==========================================\n",
        "# DATASET\n",
        "# ==========================================\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ==========================================\n",
        "# METRICS\n",
        "# ==========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-predictions))\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1_per_class = f1_score(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "    metrics = {'f1_macro': f1_macro}\n",
        "    for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "        metrics[f'f1_{col}'] = f1_per_class[i]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ==========================================\n",
        "# CLASS-WEIGHTED TRAINER\n",
        "# ==========================================\n",
        "class WeightedMultiLabelTrainer(Trainer):\n",
        "    def __init__(self, pos_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.pos_weights = pos_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights.to(model.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ==========================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def optimize_thresholds(val_probs, val_labels, label_names):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"THRESHOLD OPTIMIZATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    best_thresholds = []\n",
        "\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        best_thresh = 0.5\n",
        "        best_f1 = 0\n",
        "\n",
        "        # Scan thresholds\n",
        "        for thresh in np.arange(0.1, 0.9, 0.05):\n",
        "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
        "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        best_thresholds.append(best_thresh)\n",
        "        print(f\"{label_name:20s}: threshold={best_thresh:.2f}, F1={best_f1:.4f}\")\n",
        "\n",
        "    return np.array(best_thresholds)\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 1: FIND THRESHOLDS\n",
        "# ==========================================\n",
        "def stage1_find_thresholds(train_df):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 1: Threshold Optimization\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Split\n",
        "    has_label = (train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).astype(int)\n",
        "    train_data, val_data = train_test_split(\n",
        "        train_df,\n",
        "        test_size=Config.VAL_SIZE,\n",
        "        random_state=Config.SEED,\n",
        "        stratify=has_label\n",
        "    )\n",
        "\n",
        "    print(f\"\\n📊 Split: {len(train_data)} train, {len(val_data)} val\")\n",
        "\n",
        "    # Calculate class weights\n",
        "    pos_counts = train_data[Config.LABEL_COLUMNS].sum()\n",
        "    neg_counts = len(train_data) - pos_counts\n",
        "    pos_weights = neg_counts / (pos_counts + 1e-5)\n",
        "    pos_weights_tensor = torch.tensor(pos_weights.values, dtype=torch.float)\n",
        "\n",
        "    print(f\"\\nClass weights:\")\n",
        "    for col, weight in zip(Config.LABEL_COLUMNS, pos_weights):\n",
        "        print(f\"  {col:20s}: {weight:.3f}\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        ignore_mismatched_sizes=True,\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_data['text'].tolist(),\n",
        "        train_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "    val_dataset = MultiLabelDataset(\n",
        "        val_data['text'].tolist(),\n",
        "        val_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_eng_s3_stage1\",\n",
        "        num_train_epochs=Config.STAGE1_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer = WeightedMultiLabelTrainer(\n",
        "        pos_weights=pos_weights_tensor,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Stage 1...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\n✅ Stage 1 Results:\")\n",
        "    print(f\"  F1 Macro: {eval_metrics['eval_f1_macro']:.4f}\")\n",
        "    print(f\"\\n  Per-class F1:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        print(f\"    {col:20s}: {eval_metrics[f'eval_f1_{col}']:.4f}\")\n",
        "\n",
        "    # Get predictions\n",
        "    val_predictions = trainer.predict(val_dataset)\n",
        "    val_logits = val_predictions.predictions\n",
        "    val_probs = 1 / (1 + np.exp(-val_logits))\n",
        "    val_labels = val_data[Config.LABEL_COLUMNS].values\n",
        "\n",
        "    # Optimize thresholds\n",
        "    best_thresholds = optimize_thresholds(val_probs, val_labels, Config.LABEL_COLUMNS)\n",
        "\n",
        "    # Calculate optimized F1\n",
        "    val_preds_optimized = np.zeros_like(val_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        val_preds_optimized[:, i] = (val_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    optimized_f1 = f1_score(val_labels, val_preds_optimized, average='macro', zero_division=0)\n",
        "    print(f\"\\n🎯 Optimized Validation F1: {optimized_f1:.4f}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 2: FINAL MODEL\n",
        "# ==========================================\n",
        "def stage2_train_final(train_df, test_df, best_thresholds):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 2: Final Model Training (All Data)\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Training on ALL {len(train_df)} samples\")\n",
        "\n",
        "    # Calculate class weights on full dataset\n",
        "    pos_counts = train_df[Config.LABEL_COLUMNS].sum()\n",
        "    neg_counts = len(train_df) - pos_counts\n",
        "    pos_weights = neg_counts / (pos_counts + 1e-5)\n",
        "    pos_weights_tensor = torch.tensor(pos_weights.values, dtype=torch.float)\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        ignore_mismatched_sizes=True,\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Dataset\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_eng_s3_stage2\",\n",
        "        num_train_epochs=Config.STAGE2_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer = WeightedMultiLabelTrainer(\n",
        "        pos_weights=pos_weights_tensor,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Final Model...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predict\n",
        "    print(f\"\\n📊 Predicting on test set...\")\n",
        "    test_dataset = MultiLabelDataset(\n",
        "        test_df['text'].tolist(),\n",
        "        np.zeros((len(test_df), len(Config.LABEL_COLUMNS))),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    test_predictions = trainer.predict(test_dataset)\n",
        "    test_logits = test_predictions.predictions\n",
        "    test_probs = 1 / (1 + np.exp(-test_logits))\n",
        "\n",
        "    # Apply thresholds\n",
        "    final_preds = np.zeros_like(test_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        final_preds[:, i] = (test_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# English Subtask 3: Two-Stage Training\")\n",
        "    print(f\"# Manifestation Identification\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Load\n",
        "    print(f\"\\n📂 Loading data...\")\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(Config.TEST_PATH)\n",
        "\n",
        "    # Clean\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].fillna(0).astype(int)\n",
        "\n",
        "    print(f\"✅ Train: {len(train_df)} samples\")\n",
        "    print(f\"✅ Test: {len(test_df)} samples (blind)\")\n",
        "\n",
        "    # Stats\n",
        "    print(f\"\\n📊 Dataset Characteristics:\")\n",
        "    label_sums = train_df[Config.LABEL_COLUMNS].sum(axis=1)\n",
        "    print(f\"  Multi-label density: {100*(label_sums > 1).mean():.1f}%\")\n",
        "    print(f\"  Avg labels/sample: {label_sums.mean():.2f}\")\n",
        "\n",
        "    print(f\"\\n🏷️  Label Distribution:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        count = train_df[col].sum()\n",
        "        pct = 100 * train_df[col].mean()\n",
        "        print(f\"  {col:20s}: {count:4d} ({pct:5.2f}%)\")\n",
        "\n",
        "    # Stage 1\n",
        "    best_thresholds = stage1_find_thresholds(train_df)\n",
        "\n",
        "    # Stage 2\n",
        "    if Config.TRAIN_FINAL_MODEL:\n",
        "        final_preds = stage2_train_final(train_df, test_df, best_thresholds)\n",
        "\n",
        "        # Save\n",
        "        print(f\"\\n💾 Saving predictions...\")\n",
        "        submission = pd.DataFrame(final_preds, columns=Config.LABEL_COLUMNS)\n",
        "        submission.insert(0, 'id', test_df['id'])\n",
        "        submission.to_csv(Config.OUTPUT_PATH, index=False)\n",
        "\n",
        "        print(f\"\\n✅ Saved: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "        # Stats\n",
        "        print(f\"\\n📊 Prediction Distribution:\")\n",
        "        for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "            count = final_preds[:, i].sum()\n",
        "            pct = 100 * count / len(final_preds)\n",
        "            print(f\"  {col:20s}: {count:3d} ({pct:5.2f}%)\")\n",
        "\n",
        "        label_sums = final_preds.sum(axis=1)\n",
        "        no_labels = (label_sums == 0).sum()\n",
        "        multi_labels = (label_sums > 1).sum()\n",
        "        print(f\"\\n  No labels: {no_labels} ({100*no_labels/len(final_preds):.1f}%)\")\n",
        "        print(f\"  Multi-label: {multi_labels} ({100*multi_labels/len(final_preds):.1f}%)\")\n",
        "    else:\n",
        "        print(f\"\\n⭐ Skipping Stage 2\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✅ COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thresholds = main()\n",
        "    print(\"\\n✨ Done!\")"
      ],
      "metadata": {
        "id": "7fseV-hqT1ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d1cc32d-abe5-48d4-d2c3-44cc2167cf32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################################################\n",
            "# English Subtask 3: Two-Stage Training\n",
            "# Manifestation Identification\n",
            "############################################################\n",
            "\n",
            "📂 Loading data...\n",
            "✅ Train: 3222 samples\n",
            "✅ Test: 160 samples (blind)\n",
            "\n",
            "📊 Dataset Characteristics:\n",
            "  Multi-label density: 31.2%\n",
            "  Avg labels/sample: 1.07\n",
            "\n",
            "🏷️  Label Distribution:\n",
            "  stereotype          :  487 (15.11%)\n",
            "  vilification        :  858 (26.63%)\n",
            "  dehumanization      :  391 (12.14%)\n",
            "  extreme_language    :  770 (23.90%)\n",
            "  lack_of_empathy     :  357 (11.08%)\n",
            "  invalidation        :  586 (18.19%)\n",
            "\n",
            "############################################################\n",
            "# STAGE 1: Threshold Optimization\n",
            "############################################################\n",
            "\n",
            "📊 Split: 2577 train, 645 val\n",
            "\n",
            "Class weights:\n",
            "  stereotype          : 5.642\n",
            "  vilification        : 2.746\n",
            "  dehumanization      : 7.207\n",
            "  extreme_language    : 3.204\n",
            "  lack_of_empathy     : 8.204\n",
            "  invalidation        : 4.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Stage 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [405/405 02:22, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Stereotype</th>\n",
              "      <th>F1 Vilification</th>\n",
              "      <th>F1 Dehumanization</th>\n",
              "      <th>F1 Extreme Language</th>\n",
              "      <th>F1 Lack Of Empathy</th>\n",
              "      <th>F1 Invalidation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.039700</td>\n",
              "      <td>0.910913</td>\n",
              "      <td>0.446175</td>\n",
              "      <td>0.410714</td>\n",
              "      <td>0.616570</td>\n",
              "      <td>0.340426</td>\n",
              "      <td>0.566406</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.430435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.801900</td>\n",
              "      <td>0.861368</td>\n",
              "      <td>0.494892</td>\n",
              "      <td>0.477064</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>0.408027</td>\n",
              "      <td>0.608911</td>\n",
              "      <td>0.345912</td>\n",
              "      <td>0.470899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.768800</td>\n",
              "      <td>0.866477</td>\n",
              "      <td>0.503219</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.683603</td>\n",
              "      <td>0.419753</td>\n",
              "      <td>0.621495</td>\n",
              "      <td>0.362018</td>\n",
              "      <td>0.452442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.671400</td>\n",
              "      <td>0.897485</td>\n",
              "      <td>0.508935</td>\n",
              "      <td>0.498516</td>\n",
              "      <td>0.679426</td>\n",
              "      <td>0.431894</td>\n",
              "      <td>0.622549</td>\n",
              "      <td>0.354740</td>\n",
              "      <td>0.466488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.600500</td>\n",
              "      <td>0.895010</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.695864</td>\n",
              "      <td>0.436860</td>\n",
              "      <td>0.625310</td>\n",
              "      <td>0.369427</td>\n",
              "      <td>0.468665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stage 1 Results:\n",
            "  F1 Macro: 0.5178\n",
            "\n",
            "  Per-class F1:\n",
            "    stereotype          : 0.5106\n",
            "    vilification        : 0.6959\n",
            "    dehumanization      : 0.4369\n",
            "    extreme_language    : 0.6253\n",
            "    lack_of_empathy     : 0.3694\n",
            "    invalidation        : 0.4687\n",
            "\n",
            "============================================================\n",
            "THRESHOLD OPTIMIZATION\n",
            "============================================================\n",
            "stereotype          : threshold=0.65, F1=0.5246\n",
            "vilification        : threshold=0.65, F1=0.7020\n",
            "dehumanization      : threshold=0.80, F1=0.4631\n",
            "extreme_language    : threshold=0.65, F1=0.6440\n",
            "lack_of_empathy     : threshold=0.70, F1=0.3831\n",
            "invalidation        : threshold=0.70, F1=0.4940\n",
            "\n",
            "🎯 Optimized Validation F1: 0.5351\n",
            "\n",
            "############################################################\n",
            "# STAGE 2: Final Model Training (All Data)\n",
            "############################################################\n",
            "\n",
            "📊 Training on ALL 3222 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Final Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='606' max='606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [606/606 01:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.068100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.833900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.836900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.750900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.736800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.677600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.630700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.625800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.594300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Predicting on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving predictions...\n",
            "\n",
            "✅ Saved: /content/gdrive/MyDrive/SemEval/dev_phase/subtask3/pred_eng_two_stage.csv\n",
            "\n",
            "📊 Prediction Distribution:\n",
            "  stereotype          :  41 (25.62%)\n",
            "  vilification        :  49 (30.62%)\n",
            "  dehumanization      :  26 (16.25%)\n",
            "  extreme_language    :  48 (30.00%)\n",
            "  lack_of_empathy     :  33 (20.62%)\n",
            "  invalidation        :  48 (30.00%)\n",
            "\n",
            "  No labels: 107 (66.9%)\n",
            "  Multi-label: 48 (30.0%)\n",
            "\n",
            "============================================================\n",
            "✅ COMPLETE!\n",
            "============================================================\n",
            "\n",
            "✨ Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## arabic"
      ],
      "metadata": {
        "id": "526rgt4LARqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FIXED: Arabic Subtask 3 with MARBERT\n",
        "Manifestation Identification\n",
        "\n",
        "Optimized for Arabic characteristics:\n",
        "- Higher multi-label density (39% vs 13%)\n",
        "- Strong correlations (0.65-0.66 between top labels)\n",
        "- Average 1.37 labels per sample\n",
        "- Better class balance (4.6:1 vs English)\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    # Paths\n",
        "\n",
        "    TRAIN_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/train/arb.csv\"\n",
        "    TEST_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/dev/arb.csv\"\n",
        "    OUTPUT_PATH = \"/content/gdrive/MyDrive/SemEval/dev_phase/subtask3/pred_arb_marbert.csv\"\n",
        "\n",
        "    # Labels - 6 manifestation types\n",
        "    LABEL_COLUMNS = [\n",
        "        'vilification',\n",
        "        'extreme_language',\n",
        "        'stereotype',\n",
        "        'invalidation',\n",
        "        'lack_of_empathy',\n",
        "        'dehumanization'\n",
        "    ]\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "    # MODEL_NAME = \"UBC-NLP/MARBERT\"\n",
        "    MAX_LENGTH = 96\n",
        "\n",
        "    # Training\n",
        "    STAGE1_EPOCHS = 5\n",
        "    STAGE2_EPOCHS = 6\n",
        "    BATCH_SIZE = 16\n",
        "    EVAL_BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 2e-5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    WARMUP_RATIO = 0.1\n",
        "    VAL_SIZE = 0.2\n",
        "\n",
        "    # Regularization\n",
        "    HIDDEN_DROPOUT = 0.1  # Reduced (better balance)\n",
        "    ATTENTION_DROPOUT = 0.1\n",
        "\n",
        "    # Loss\n",
        "    USE_FOCAL_LOSS = True\n",
        "    FOCAL_ALPHA = 0.25\n",
        "    FOCAL_GAMMA = 1.5  # Reduced (better balance than English)\n",
        "\n",
        "    # Other\n",
        "    SEED = 42\n",
        "    USE_FP16 = True\n",
        "    TRAIN_FINAL_MODEL = True\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(Config.SEED)\n",
        "\n",
        "# ==========================================\n",
        "# FOCAL LOSS\n",
        "# ==========================================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# ==========================================\n",
        "# DATASET\n",
        "# ==========================================\n",
        "class MultiLabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=96):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "# ==========================================\n",
        "# METRICS\n",
        "# ==========================================\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-predictions))\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)\n",
        "    f1_per_class = f1_score(labels, preds, average=None, zero_division=0)\n",
        "\n",
        "    metrics = {'f1_macro': f1_macro}\n",
        "    for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "        metrics[f'f1_{col}'] = f1_per_class[i]\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ==========================================\n",
        "# TRAINER\n",
        "# ==========================================\n",
        "class FocalLossTrainer(Trainer):\n",
        "    def __init__(self, focal_loss_fn, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.focal_loss_fn = focal_loss_fn\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.focal_loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# ==========================================\n",
        "# THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def optimize_thresholds(val_probs, val_labels, label_names):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"THRESHOLD OPTIMIZATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    best_thresholds = []\n",
        "\n",
        "    for i, label_name in enumerate(label_names):\n",
        "        best_thresh = 0.5\n",
        "        best_f1 = 0\n",
        "\n",
        "        # Scan thresholds\n",
        "        for thresh in np.arange(0.2, 0.7, 0.05):\n",
        "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
        "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        best_thresholds.append(best_thresh)\n",
        "        print(f\"{label_name:25s}: threshold={best_thresh:.2f}, F1={best_f1:.4f}\")\n",
        "\n",
        "    return np.array(best_thresholds)\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 1: THRESHOLD OPTIMIZATION\n",
        "# ==========================================\n",
        "def stage1_find_thresholds(train_df):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 1: Threshold Optimization\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Split\n",
        "    has_label = (train_df[Config.LABEL_COLUMNS].sum(axis=1) > 0).astype(int)\n",
        "    train_data, val_data = train_test_split(\n",
        "        train_df,\n",
        "        test_size=Config.VAL_SIZE,\n",
        "        random_state=Config.SEED,\n",
        "        stratify=has_label\n",
        "    )\n",
        "\n",
        "    print(f\"\\n📊 Split: {len(train_data)} train, {len(val_data)} val\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_data['text'].tolist(),\n",
        "        train_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "    val_dataset = MultiLabelDataset(\n",
        "        val_data['text'].tolist(),\n",
        "        val_data[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_s3_stage1\",\n",
        "        num_train_epochs=Config.STAGE1_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Stage 1...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\n✅ Stage 1 Results:\")\n",
        "    print(f\"  F1 Macro: {eval_metrics['eval_f1_macro']:.4f}\")\n",
        "    print(f\"\\n  Per-class F1:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        print(f\"    {col:25s}: {eval_metrics[f'eval_f1_{col}']:.4f}\")\n",
        "\n",
        "    # Get predictions\n",
        "    val_predictions = trainer.predict(val_dataset)\n",
        "    val_logits = val_predictions.predictions\n",
        "    val_probs = 1 / (1 + np.exp(-val_logits))\n",
        "    val_labels = val_data[Config.LABEL_COLUMNS].values\n",
        "\n",
        "    # Optimize thresholds\n",
        "    best_thresholds = optimize_thresholds(val_probs, val_labels, Config.LABEL_COLUMNS)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "# ==========================================\n",
        "# STAGE 2: FINAL MODEL\n",
        "# ==========================================\n",
        "def stage2_train_final(train_df, test_df, best_thresholds):\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# STAGE 2: Final Model Training\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Training on ALL {len(train_df)} samples\")\n",
        "\n",
        "    # Initialize\n",
        "    tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        Config.MODEL_NAME,\n",
        "        num_labels=len(Config.LABEL_COLUMNS),\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        hidden_dropout_prob=Config.HIDDEN_DROPOUT,\n",
        "        attention_probs_dropout_prob=Config.ATTENTION_DROPOUT\n",
        "    )\n",
        "\n",
        "    # Dataset\n",
        "    train_dataset = MultiLabelDataset(\n",
        "        train_df['text'].tolist(),\n",
        "        train_df[Config.LABEL_COLUMNS].values,\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Training args\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results_s3_stage2\",\n",
        "        num_train_epochs=Config.STAGE2_EPOCHS,\n",
        "        learning_rate=Config.LEARNING_RATE,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=2,\n",
        "        weight_decay=Config.WEIGHT_DECAY,\n",
        "        warmup_ratio=Config.WARMUP_RATIO,\n",
        "        fp16=Config.USE_FP16,\n",
        "        logging_steps=50,\n",
        "        save_strategy=\"no\",\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    focal_loss = FocalLoss(alpha=Config.FOCAL_ALPHA, gamma=Config.FOCAL_GAMMA)\n",
        "    trainer = FocalLossTrainer(\n",
        "        focal_loss_fn=focal_loss,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Training Final Model...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predict\n",
        "    print(f\"\\n📊 Predicting on test set...\")\n",
        "    test_dataset = MultiLabelDataset(\n",
        "        test_df['text'].tolist(),\n",
        "        np.zeros((len(test_df), len(Config.LABEL_COLUMNS))),\n",
        "        tokenizer,\n",
        "        max_length=Config.MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    test_predictions = trainer.predict(test_dataset)\n",
        "    test_logits = test_predictions.predictions\n",
        "    test_probs = 1 / (1 + np.exp(-test_logits))\n",
        "\n",
        "    # Apply thresholds\n",
        "    final_preds = np.zeros_like(test_probs, dtype=int)\n",
        "    for i, thresh in enumerate(best_thresholds):\n",
        "        final_preds[:, i] = (test_probs[:, i] >= thresh).astype(int)\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return final_preds\n",
        "\n",
        "# ==========================================\n",
        "# MAIN\n",
        "# ==========================================\n",
        "def main():\n",
        "    print(f\"\\n{'#'*60}\")\n",
        "    print(f\"# Arabic Subtask 3: Two-Stage Training\")\n",
        "    print(f\"# Manifestation Identification (6 labels)\")\n",
        "    print(f\"{'#'*60}\")\n",
        "\n",
        "    # Load\n",
        "    print(f\"\\n📂 Loading data...\")\n",
        "    train_df = pd.read_csv(Config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(Config.TEST_PATH)\n",
        "\n",
        "    # Clean\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].fillna(0).astype(int)\n",
        "\n",
        "    print(f\"✅ Train: {len(train_df)} samples\")\n",
        "    print(f\"✅ Test: {len(test_df)} samples (blind)\")\n",
        "\n",
        "    # Stats\n",
        "    print(f\"\\n📊 Arabic Subtask 3 Characteristics:\")\n",
        "    print(f\"  Multi-label density: {100*(train_df[Config.LABEL_COLUMNS].sum(axis=1) > 1).mean():.1f}%\")\n",
        "    print(f\"  Avg labels/sample: {train_df[Config.LABEL_COLUMNS].sum(axis=1).mean():.2f}\")\n",
        "\n",
        "    print(f\"\\n🏷️  Label Distribution:\")\n",
        "    for col in Config.LABEL_COLUMNS:\n",
        "        count = train_df[col].sum()\n",
        "        pct = 100 * train_df[col].mean()\n",
        "        print(f\"  {col:25s}: {count:4d} ({pct:5.2f}%)\")\n",
        "\n",
        "    # Stage 1\n",
        "    best_thresholds = stage1_find_thresholds(train_df)\n",
        "\n",
        "    # Stage 2\n",
        "    if Config.TRAIN_FINAL_MODEL:\n",
        "        final_preds = stage2_train_final(train_df, test_df, best_thresholds)\n",
        "\n",
        "        # Save\n",
        "        print(f\"\\n💾 Saving predictions...\")\n",
        "        submission = pd.DataFrame(final_preds, columns=Config.LABEL_COLUMNS)\n",
        "        submission.insert(0, 'id', test_df['id'])\n",
        "        submission.to_csv(Config.OUTPUT_PATH, index=False)\n",
        "\n",
        "        print(f\"\\n✅ Saved: {Config.OUTPUT_PATH}\")\n",
        "\n",
        "        # Stats\n",
        "        print(f\"\\n📊 Prediction Distribution:\")\n",
        "        for i, col in enumerate(Config.LABEL_COLUMNS):\n",
        "            count = final_preds[:, i].sum()\n",
        "            pct = 100 * count / len(final_preds)\n",
        "            print(f\"  {col:25s}: {count:3d} ({pct:5.2f}%)\")\n",
        "\n",
        "        no_labels = (final_preds.sum(axis=1) == 0).sum()\n",
        "        multi_labels = (final_preds.sum(axis=1) > 1).sum()\n",
        "        print(f\"\\n  No labels: {no_labels} ({100*no_labels/len(final_preds):.1f}%)\")\n",
        "        print(f\"  Multi-label: {multi_labels} ({100*multi_labels/len(final_preds):.1f}%)\")\n",
        "    else:\n",
        "        print(f\"\\n⏭️  Skipping Stage 2\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✅ COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thresholds = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "bb86a554ed5d4abb8b4f338827cb305f",
            "ce519754f49b491784fe62512c96eada",
            "9a215e7a98384821a2b66439300527e2",
            "b1743b7e790c45a5bef6dde259eba05a",
            "6b7cc17b4ad54d38b8536600d6b91792",
            "152bc6d18d74443abfd7609a42e98b23",
            "59065b9732a9435789ac077f35dcbf8d",
            "99d7bed6f5514cbe9dd6808a3e190089",
            "9c8800b7a4d64232bcdf6dcf1339ea4e",
            "7e2d592e20f540ed8691150a83a2a63a",
            "d19449e627144150936cf82112d6695c"
          ]
        },
        "id": "NFViR2ElAU6t",
        "outputId": "d37a4419-dd70-484c-d4e9-5d0552186e7d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################################################\n",
            "# Arabic Subtask 3: Two-Stage Training\n",
            "# Manifestation Identification (6 labels)\n",
            "############################################################\n",
            "\n",
            "📂 Loading data...\n",
            "✅ Train: 3380 samples\n",
            "✅ Test: 169 samples (blind)\n",
            "\n",
            "📊 Arabic Subtask 3 Characteristics:\n",
            "  Multi-label density: 39.0%\n",
            "  Avg labels/sample: 1.37\n",
            "\n",
            "🏷️  Label Distribution:\n",
            "  vilification             : 1256 (37.16%)\n",
            "  extreme_language         : 1027 (30.38%)\n",
            "  stereotype               : 1127 (33.34%)\n",
            "  invalidation             :  274 ( 8.11%)\n",
            "  lack_of_empathy          :  575 (17.01%)\n",
            "  dehumanization           :  370 (10.95%)\n",
            "\n",
            "############################################################\n",
            "# STAGE 1: Threshold Optimization\n",
            "############################################################\n",
            "\n",
            "📊 Split: 2704 train, 676 val\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb86a554ed5d4abb8b4f338827cb305f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Stage 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [425/425 06:13, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Vilification</th>\n",
              "      <th>F1 Extreme Language</th>\n",
              "      <th>F1 Stereotype</th>\n",
              "      <th>F1 Invalidation</th>\n",
              "      <th>F1 Lack Of Empathy</th>\n",
              "      <th>F1 Dehumanization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.051900</td>\n",
              "      <td>0.043796</td>\n",
              "      <td>0.075142</td>\n",
              "      <td>0.367347</td>\n",
              "      <td>0.009434</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.037300</td>\n",
              "      <td>0.037757</td>\n",
              "      <td>0.274213</td>\n",
              "      <td>0.646943</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.518337</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.033000</td>\n",
              "      <td>0.038418</td>\n",
              "      <td>0.392968</td>\n",
              "      <td>0.665574</td>\n",
              "      <td>0.641975</td>\n",
              "      <td>0.635514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.414747</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.038121</td>\n",
              "      <td>0.379516</td>\n",
              "      <td>0.662921</td>\n",
              "      <td>0.612048</td>\n",
              "      <td>0.632911</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.336957</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.027000</td>\n",
              "      <td>0.039822</td>\n",
              "      <td>0.410979</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.580808</td>\n",
              "      <td>0.601399</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.312849</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Stage 1 Results:\n",
            "  F1 Macro: 0.4110\n",
            "\n",
            "  Per-class F1:\n",
            "    vilification             : 0.6452\n",
            "    extreme_language         : 0.5808\n",
            "    stereotype               : 0.6014\n",
            "    invalidation             : 0.2632\n",
            "    lack_of_empathy          : 0.3128\n",
            "    dehumanization           : 0.0625\n",
            "\n",
            "============================================================\n",
            "THRESHOLD OPTIMIZATION\n",
            "============================================================\n",
            "vilification             : threshold=0.35, F1=0.6710\n",
            "extreme_language         : threshold=0.35, F1=0.6490\n",
            "stereotype               : threshold=0.35, F1=0.6426\n",
            "invalidation             : threshold=0.35, F1=0.3727\n",
            "lack_of_empathy          : threshold=0.40, F1=0.4751\n",
            "dehumanization           : threshold=0.25, F1=0.3515\n",
            "\n",
            "############################################################\n",
            "# STAGE 2: Final Model Training\n",
            "############################################################\n",
            "\n",
            "📊 Training on ALL 3380 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Training Final Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [636/636 01:54, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.047900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.039400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.030100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.025200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.023200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.019900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Predicting on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving predictions...\n",
            "\n",
            "✅ Saved: /content/gdrive/MyDrive/SemEval/dev_phase/subtask3/pred_arb_marbert.csv\n",
            "\n",
            "📊 Prediction Distribution:\n",
            "  vilification             :  69 (40.83%)\n",
            "  extreme_language         :  61 (36.09%)\n",
            "  stereotype               :  63 (37.28%)\n",
            "  invalidation             :  14 ( 8.28%)\n",
            "  lack_of_empathy          :  30 (17.75%)\n",
            "  dehumanization           :  41 (24.26%)\n",
            "\n",
            "  No labels: 97 (57.4%)\n",
            "  Multi-label: 64 (37.9%)\n",
            "\n",
            "============================================================\n",
            "✅ COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}